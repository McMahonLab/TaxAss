RRR 12-5-15

This workflow assigns taxonomy to a fasta file of otu sequences using both a 
small, custom taxonomy database and a large general database.

Summary of Steps and Commands (all commands entered in terminal window):

-1. background on why we chose this workflow

0. format files (textwrangler or bash)
	depends on your starting file formats
	for Green Genes database as general.taxonomy:
		sed 's/ //g' <general.taxonomy >NoSpaces
		sed 's/$/;/' <NoSpaces >EndLineSemicolons
		mv EndLineSemicolons general.taxonomy
		rm NoSpaces
		
1. make BLAST database file (blast)
	makeblastdb -dbtype nucl -in custom.fasta -input_type fasta -parse_seqids -out custom.db

2. run BLAST (blast)
	blastn -query otus.fasta -task megablast -db custom.db -out otus.custom.blast -outfmt 11 -max_target_seqs 5

3. reformat blast results (blast)
	blast_formatter -archive otus.custom.blast -outfmt "6 qseqid pident length qlen qstart qend" -out otus.custom.blast.table

4. filter BLAST results (R)
	Rscript calc_full_length_pident.R otus.custom.blast.table otus.custom.blast.table.modified
	Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.above.98 98 TRUE 
	Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.below.98 98 FALSE

5. check that BLAST settings are appropriate (R)
	mkdir plots
	RScript plot_blast_hit_stats.R otus.custom.blast.table.modified 98 plots

6. recover sequence IDs left out of blast (python, bash)
	python find_seqIDs_blast_removed.py otus.fasta otus.custom.blast.table.modified ids.below.98
	
7. create fasta files of desired sequence IDs (python)
	python create_fastas_given_seqIDs.py ids.above.98 otus.fasta otus.above.98.fasta
	python create_fastas_given_seqIDs.py ids.below.98 otus.fasta otus.below.98.fasta

8. assign taxonomy (mothur)
	mothur "#classify.seqs(fasta=otus.above.98.fasta, template=custom.fasta,  taxonomy=custom.taxonomy, method=wang, probs=T, processors=2)"
	mothur "#classify.seqs(fasta=otus.below.98.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"

9. combine taxonomy files (terminal)
	cat otus.above.98.custom.wang.taxonomy otus.below.98.general.wang.taxonomy > otus.98.taxonomy

10. assign taxonomy with general database only (mothur, bash)
	mothur "#classify.seqs(fasta=otus.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
	cat otus.general.wang.taxonomy > otus.general.taxonomy

11. assign taxonomy to custom database with general database (mothur, bash)
	mothur "#classify.seqs(fasta=custom.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
	mv custom.general.wang.taxonomy custom.general.taxonomy

12. reformat taxonomy files (bash)
	sed 's/[[:blank:]]/\;/' <otus.98.taxonomy >otus.98.taxonomy.reformatted
	mv otus.98.taxonomy.reformatted otus.98.taxonomy
	sed 's/[[:blank:]]/\;/' <otus.general.taxonomy >otus.general.taxonomy.reformatted
	mv otus.general.taxonomy.reformatted otus.general.taxonomy
	sed 's/[[:blank:]]/\;/' <custom.general.taxonomy >custom.general.taxonomy.reformatted
	mv custom.general.taxonomy.reformatted custom.general.taxonomy
	sed 's/[[:blank:]]/\;/' <custom.taxonomy >custom.custom.taxonomy
	
13. compare taxonomy files (R)
	mkdir conflicts_98
	Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 85 70
	mkdir conflicts_database
	Rscript find_classification_disagreements.R custom.custom.taxonomy custom.general.taxonomy NA conflicts_database NA NA 70 database 

14. choose appropriate pident cutoff (R)
	Rscript plot_classification_disagreements.R otus.abund plots conflicts_database conflicts_94 ids.above.94 94 conflicts_96 ids.above.96 96 conflicts_98 ids.above.98 98

15. generate final taxonomy file (R)
	Rscript find_classification_disagreements.R otus.98.taxonomy NA ids.above.98 conflicts_98 98 85 70 final

16. tidy up (bash)
	rm custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy
	mkdir scripts
	mv *.py *.R *.sh scripts/
	mkdir analysis/
	mv conflicts* plots/ analysis/
	mkdir data
	mv otus* data/
	mkdir databases
	mv *.taxonomy *.fasta databases
	
Detailed explanations of commands and inputs are below:


__________________________________________________________________________________________

-1. background on why we chose this workflow

Our original taxonomy assignment workflow was straightforward and more simple: 
	everything was classified to 70% using our FW database
	all classifications that weren't "unclassified" at the lineage level were kept
	everything else was re-classified using green genes to 60%

However this workflow was flawed due to a misunderstanding of the classification p values:
	-The 70% bootstrap value refers to the repeatability of the taxonomy assignment,
	NOT to it's accuracy.
	-A classification that is given at 70% confidence means that 70% of the time 
	when you feed that sequence into that database it goes into that group.
	-The classifier sill puts anything you feed into it a classification, 
	even it the true classification is not included in the database.
	-The GG database is huge, if you put something into it that the database doesn't have,
	it will likely put it in random different clusters each time and it will be "unclassified"
	-Our database is small.  If you put something into it that it doesn't have,
	it fill find whatever it's closest to and consistently call it that because there are 
	not as many dissimilar options to spread it between.
		consistently. meaning a high bootstrap value.
	-simple example: if you give our FW database an archaea sequence, 100% of the time
	it will say it is a bacteria- because the database only has bacteria in it.

Consequences of the flaw:
	-we were forcing sequences that do not match well to be called our favorite FW taxa
		-we may have missed other taxa that may be important
		-we may have muddied the relationships of our key taxa by adding in unrelated ones

Possible solutions and why they don't work:
	-Classify in GG first
		-then reclassify the "freshwater" phylums.
		-this is basically what Jason did to solve the problem
		-but phyla are too broad in GG, can't assume everything in phylum is in our database
	-Classify in GG first
		-then reclassify the "freshwater" orders (or some lower level)
		-but GG lacks the resolution to identify those orders,
		we'd miss many sequences b/c GG would call them unclassified
	-Combine the two taxonomy databases and classify all at once
		-if something is present in both databases, it will be split during classification,
		50% going into one, the other 50% into the other, and remain unclassified
	-Classify our sequences with green genes, remove those green genes sequences, and then
	combine the databases and classify all at once
		-the taxonomy databases are highly curated, adding something new in is not that simple.
			-the structure of the two databases may differ at higher taxonomic resolution
			-the green genes classification might not actually be a good match if the freshwater
			sequence just doesn't exist in green genes, so then we'd be removing an unrelated
			sequence that we shouldn't.
				-how can you differentiate if the fw sequence does not exist in gg
				or if the fw sequence exists in gg but is only named to class level.
	-Classify the sequences in the freshwater database with a different method, like BLAST,
	since it's a small database anyway.
		-the taxonomy assignment algorithm takes into consideration phylogeny, which is a
		better classification that by just using sequence similarity.
	
Our solution/this workflow (that we think works):
	-Classify in FW first, but with a cutoff not based on clustering bootstrap values
		-use a BLAST cutoff to identify highly similar sequences to those in
		our freshwater sequence database
		-classify those hightly similar sequences with a classification algorithm and our db
		-classify the remaining sequences with a large database
		

__________________________________________________________________________________________

0. format files (textwrangler or bash)

These are the files you supply as input into the workflow:
	custom.fasta		fasta sequences in your small, specific taxonomy database
	custom.taxonomy		taxonomy names in your small, specific taxonomy database
	general.fasta		fasta sequences in your large, general taxonomy database
	general.taxonomy	taxonomy names in your large, general taxonomy database
	otus.fasta			fasta sequences for each of your OTUs
	otus.abund			relative abundance of each OTU (i.e. the OTU table)

I recommend you move all of these files into a new folder that also contains the workflow scripts, 
and rename them to match the above names so that you can copy and paste commands from this workflow.
Also put the script files in this workflow into that same folder.
Then make that folder your working directory for the entirety of this workflow.

Reformat your files so that:

1. .taxonomy files: 
		-must be compatible with mothur, example format:
		
			seqID tab kingdom;phylum;class;order;family;genus;species;
		
		-no whitespace except for the tab between seqID and taxonomy
		-taxonomy level names separated by semicolons
		-must have a semicolon at the end of each line, too!
		
		-If you are using the Green Genes taxonomy database, you can reformat it this way: 

Full 4 Commands (type in terminal) when general.taxonomy is the green genes taxonomy file:

sed 's/ //g' <general.taxonomy >NoSpaces
sed 's/$/;/' <NoSpaces >EndLineSemicolons
mv EndLineSemicolons general.taxonomy
rm NoSpaces

			Syntax of commands and what each argument does:
				sed 's/find/replace/ <input >output
					sed		is a "stream editor," a function for editing streams of text in the terminal
					s		tells it you are doing a substitution
							in the first sed command that was simply a typed space
							in the second sed command the $ means 'end of line'
					replace	this is what you are replacing with
							in the first sed command it was left blank, to simply remove spaces
							in the second sed command it is a semicolon
					g		this means "global" find/replace all occurances, not just the first per line
					input	this is the file sed searches through, here it is general.taxonomy (if that is green genes!)
					output	this is the file sed creates (note it must have a different name than input)
	
				mv filename1 filename2
					mv		this is a function to move (aka rename) a file from name1 to name2
							simply keeping the edited file the same name  
				rm filename
					rm		this removes (aka deletes) the file named filename
		

			-If you are using the Silva database... no fucking clue, what does this look like??
			*************

2. OTU seqID's:
			-must match between the otus.fasta file and the otus.abund file,
			 though consistent ordering is not necessary.
			-cannot contain any whitespace
			 BLAST will call some parts the seqID and some parts comments if they're separated.
			 Having BLAST seqIDs that don't match the full >comment line of the fasta file will 
		 	 throw off the python script that finds the chosen sequences.

3. OTU files:
		-format of the OTU table otus.abund is tab delimited, seqIDs in 1st column, abundances in rest of columns:
			seqID	Abundance	Abundance	Abundance	Abundance
			seqID	Abundance	Abundance	Abundance	Abundance
			seqID	Abundance	Abundance	Abundance	Abundance
		
		-QC of your OTU sequences should be performed before you start assigning taxonomy.
		
		If you did QC in mothur, the starting files are called:
		***************
		
		If you did QC in qiime, the starting files are called:
		***************
		
__________________________________________________________________________________________

1. make BLAST database file (blast)

Use the command makeblastdb to create a blast database out of the FW taxonomy fasta files.
Need to create a database because:
	1. BLAST will run faster
	2. Having a database is necessary for some of the output formats

Full Command (type in terminal):

makeblastdb -dbtype nucl -in custom.fasta -input_type fasta -parse_seqids -out custom.db

What the filenames are:
	custom.fasta		this is the path to the small custom taxonomy file you want to use to assign
						taxonomy before using a larger taxonomy database
						(i.e. the freshwater taxonomy database fasta file)
						note: if the file path has spaces in it it needs to be ' "/path/double quoted" '
	custom.db			this is the name you choose for the blast database you are creating.
						It makes 6 files with different final extensions, but all start with this.  
						Default is your -in file name with those extensions, but it's
						less confusing to add .db so you know what the weird extension files are
What each flag does:
	-dbtype nucl		a required argument, says the database input file is nucleic acids (nucl)
	-in custom.fasta	specify path of the input file that it makes the database out of
	-input_type fasta	tells it the input file is a fasta file (that's the default value too)
	-parse_seqids		this tells it to include information in the database that will later
						allow you to pull sequences back out of it.  
						This is necessary for using blast_formatter later.
	-out custom.db		specify path of the database files this command created  

These 6 files are created:
	custom.db.nhr
	custom.db.nog
	custom.db.nsd
	custom.db.nsi
	custom.db.nsq
but later when you tell it which database file to use you just say custom.db and it figures the rest out

__________________________________________________________________________________________

2. run BLAST (blast)

Use the command blastn to run a megablast that returns the best hit in the taxonomy database (subject)
for each of your OTU sequences (queries). Megablast is optimized for finding very similar matches with
sequences longer than 30 bp.  This workflow was made for ~100 bp sequences and may need to be re-optimized
for sequences of different lengths.

Full Command (type in terminal):

blastn -query otus.fasta -task megablast -db custom.db -out otus.custom.blast -outfmt 11 -max_target_seqs 5

What the filenames are:
	otus.fasta				the query file. the fasta file of your OTU sequences you want classified
							this is what you reformatted in step 0.
	custom.db				the subject file. the blast database file you made from the taxonomy 
							database fasta sequences in step 1.
	otus.custom.blast		the BLAST output file. Its format is unreadable by you,
							but it's the detailed BLAST format that blast_formatter accepts.
							filename example here is query.subject.blast 

What each flag does:						
	-query otus.fasta 		specify path of query file
	-task megablast 		this is already optimized by smart BLAST people for high similarity hits.
							It is also the blastn default task. for more info see 
							http://www.ncbi.nlm.nih.gov/Class/MLACourse/Modules/BLAST/nucleotide_blast.html
	-db custom.db 			the name of the blast database created previously (without the additional file extensions)
	-out otus.custom.blast	specify path of the blast output file (this is the file you're creating)
	-outfmt 11 				need this format in order to use blast_formatter command
	-max_target_seqs 5		only keep the best 5 hits for each query sequence
							you will compare how good these are to check if BLAST settings are appropriate in step 5
							you can choose more or less target seqs if you want to.

__________________________________________________________________________________________

3. reformat BLAST results (blast)

The blast_formatter function in blast takes the full outformat 11 file and reformats it to any other
possible format.  Here we reformat to a custom table format to feed into the R script the pulls out
matching and nonmatching sequence IDs.
However, using blast_formatter you can look at your blast results from the previous step any way you'd like.

Full Command (type in terminal):

blast_formatter -archive otus.custom.blast -outfmt "6 qseqid pident length qlen qstart qend" -out otus.custom.blast.table

What the filenames are:
	otus.custom.blast			The blast result file generated in step 2. This is in the ASN.1 blast file format.
	otus.custom.blast.table		The blast result reformatted into a 6 column table that the R script accepts.
								The tab-delimited columns are: qseqid pident length qlen qstart qend

What each flag does:		
	-archive otus.custom.blast 		Specify path to the blast result file you are reformatting
	-outfmt "6 qseqid pident length qlen qstart qend"	
									6 is tabular format without headers or other info btwn rows of data, 
									the rest specifies what goes in each tab-delimited column:
										1 qseqid: query (OTU) sequence ID
										2 pident: percent identity (# of matches / # "columns" in the sequence)
										3 length: length of alignment
										4 qlen: full length of query sequence
										5 qstart: index of beginning of alignment on query sequence
										6 qend: index of end of alignment on query sequence
	-out otus.custom.blast.table	Specify path to the output file of formatted blast results
				
__________________________________________________________________________________________

4. filter BLAST results (R)

The filter_seqIDs_by_pident.R script takes the formatted blast file and 
calculates a "true" pident value that corrects the pident value for the entire length of the query.
I could not find any command that forces blast use the entire query sequence, so this is the workaround. 
The "true" pident is a worst case scenario that assumes any edge gaps are mismatches.
Calculation:
	"true pident" = pident * length / (length - (qend - qstart) + qlen)
The R script is run twice, once to generate the sequence ID's above/equal to the "true pident" 
cutoff that are destined for taxonomy assignment in the small custom database, once to generate
the sequence ID's below the "true pident" cutoff that are destined for taxonomy assignment
in the large general database.

Full Three Commands (type in terminal):

Rscript calc_full_length_pident.R otus.custom.blast.table otus.custom.blast.table.modified
Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.above.98 98 TRUE 
Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.below.98 98 FALSE

These arguments must be in the correct order.
Rscript sources the .R script using the arguments supplied after it in the terminal.
Separate all arguments with a space.

What each argument is:
	1st: script.R	the path to this script.  The script is called filter_seqIDs_by_pident.R
	2nd: blastfile	the path to the formatted blast file. This is the otus.custom.blast.table file from step 3
	3rd: statsfile	the path to the modified blast table you create.  This is used in step 5 to analyze the BLAST settings.
	4rd: outputfile	the path to the seqID file you are creating. This is the list of sequence ID's matching your criteria.
	5th: cutoff#	the cutoff percent identity to use. Note this is the calculated "true" full length percent identity,
					not necessarily the value blast returns for the match.  this is a number.
	6th: matches	want matches? TRUE or FALSE. TRUE: return seqID's >= cutoff, FALSE: return seqID's < cutoff

What each file is:
	filter_seqIDs_by_pident.R			the r script.  source from the command line by typing
										Rscript, not R.  Rscript accepts arguments after the script.
	otus.custom.blast.table				the formatted blast output from step 3
	otus.custom.blast.table.modified	the output file containing the modified BLAST hit table, used in step 5
										note: this is the same regardless of the cutoff chosen
	ids.above.98						the output file containing seqIDs at or above your cutoff value, used in step 7
	ids.below.98						the output file containing seqIDs below your cutoff value, used in step 6
										the format of these seqID output files are \n delimited seqIDs.
	
__________________________________________________________________________________________

5. check that BLAST settings are appropriate (R)

There is no way to force BLAST to return only full-length hits, it will always return the 
best "High Scoring Pair (HSP)" it finds, based on it's scoring that weights both the quality
and length of the hit.  However, for this use we are only interested in full length matches
because the entire OTU sequences are matched to the reference 16S sequences when assigning 
taxonomy.

High pident short HSPs will be converted to low pident "full length" HSPs because all missing
basepairs are considered a mismatch by my conservative script in step 4.  Therefore, if high 
pident short HSPs are being reported by BLAST instead of lower pident long HSPs you could 
get incorrect results.  However, the pident cutoff you will choose for taxonomy assignment 
using 16S sequences is pretty high, so while it's likely that some of the short BLAST HSPs
may have longer HSPs with better full-length pidents, it's unlikely that any of those better
ones would be good enough to meet your pident criteria. 

The likelihood of incorrect results because of BLAST chooseing HSPs that are too short increases
as the length of your OTU sequences goes up.  This step tries to check if this might
be a problem.  Generate some plots with the R script plot_blast_hit_stats.R.

Full Two Commands (type in the terminal)
mkdir plots
RScript plot_blast_hit_stats.R otus.custom.blast.table.modified 98 plots

What mkdir command does:
	mkdir		stands for "make directory", this creates a new folder
	plots		the name of the new folder you are creating
				this is where step 5 and step 14 will save plots generated for checking the cutoff

What each argument in the RScript is (keep in order and separate with a space):
	RScript								sources an R script and allows it to accept arguments from the command line
	plot_blast_hit_stats.R				the script you are sourcing
	otus.custom.blast.table.modified	the modified blast table produced in step 4.
	98									the pident cutoff used to create this BLAST table
	plots								the folder your generated plots will be saved in
	https://cran.mtu.edu				this is an OPTIONAL argument for those who
										1. don't have the "reshape" R package installed already
										2. live far away from the midwestern USA
										It's the web address to the cran mirror you use, choosing
										one close to you could make it slightly faster but
										this honestly doesn't matter much.   

What each generated file is:
	BLAST_hits_line_plot.png
	BLAST_hits_used_for_pident_98.png
	BLAST_hits_used_for_pidents_70-100.png
	BLAST_hits_used_for_pidents_90-100.png
	BLAST_hits_used_overall.png
	
*******fix all the file descriptions.  as in, add some descriptions of the plots.
old description... my new description is not very good.  come back to this.

are being chosen over lower %id longer HSPs that would have still 
met %id cutoff.
This is something that could be examined to decide if blastn custom scoring should be used instead of megablast.
However, we are only keeping very similar sequences anyway, and these sequences are very short, and
megablast is optimized with complicated statistics to find closely related sequences which we want. 
The R script in step 4 will tell you alignment length vs. query length stats so keep an eye out for this.
If many alignments are shorter then this should be examined more carefully.

Note: You may need to choose a different "true pident" cutoff for your sequence data.
I chose mine based on values that gave me classifications consistent to the class level 
between the small and large databases. You can use a supplementary R script & workflow to 
repeat this.  One thing that might affect this choice is the length of your sequences.

__________________________________________________________________________________________

6. recover sequence IDs left out of blast (python, bash)

Blast has a built in reporting cutoff based on evalue.  The blast expect value depends on
the length of the hit and the size of the database, and it reflects how frequently you 
would see a hit of that quality by chance. The default evalue cutoff is 10, which means 
blast does not report a match that you'd see 10 or more times by chance.  For more about
the evalue statistics, see: http://www.ncbi.nlm.nih.gov/BLAST/tutorial/Altschul-1.html

The python script find_seqIDs_blast_removed.py is used to find all of the 
sequence IDs in the original fasta file that do not appear in the blast output.  The python 
script then creates a new file in the same format as step 4's R script output file that
is a newline-delimited list of the missing sequence IDs.

The bash command cat concatenates these missing ids with the ids below the chosen cutoff
pident.  That is because the ids blast didn't report hits for had even worse pidents than 
the ones that didn't make the R script cutoff.

Full Command (type in terminal):

python find_seqIDs_blast_removed.py otus.fasta otus.custom.blast.table.modified ids.below.98

These arguments in the python script must be in the correct order.
python sources the .py script using the arguments supplied after it in the terminal.
Separate all arguments with a space.

What each argument is- 1st command (python):
	1st: script.py		path to this script. The script is called find_seqIDs_blast_removed.py
	2nd: fastafile		path to the fasta file containing all the seqIDs
	3rd: blastfile		path to the blast results in table format (col1 = seqID)				
	4th: outputfile		path to the file with \n delimited seqIDs the script adds to
						
What each file is:
	find_seqIDs_blast_removed.py	python script you're sourcing
	otus.fasta						original fasta file of your sequences from step 0
	otus.FW.blast.table.modified	reformatted blast results from step 4
	ids.below.98					seqIDs below your cutoff from R script in step 4 
									that the missing ones are added to in this step.
									

__________________________________________________________________________________________

7. create fasta files of desired sequence IDs (python)

The create_fastas_given_seqIDs.py takes the sequence IDs selected from the blast output 
and finds them in the original query fasta file.  
It then creates a new fasta file containing just the desired sequences.

Full Two Commands (type in terminal):

python create_fastas_given_seqIDs.py ids.above.98 otus.fasta otus.above.98.fasta
python create_fastas_given_seqIDs.py ids.below.98 otus.fasta otus.below.98.fasta

These arguments must be in the correct order.
python sources the .py script using the arguments supplied after it in the terminal.
Separate all arguments with a space.

What each argument is:
	1st: script.py	the path to this script. The script is called create_fastas_given_seqIDs.py
	2nd: idfile		the path to the file with \n separated seqIDs that was generated in step 4
	3rd: fastafile	the path to the otu fasta file containing all the seqIDs from step 0
	4th: outputfile the path to the new fasta file the script generates
					NOTE: if this file already exist the script will delete it before starting.

What each file is:
	create_fastas_given_seqIDs.py	the python script you're sourcing 
	ids.above.98					the file of seqIDs at or above your cutoff from step 4
	ids.below.98					the file of all seqIDs below your cutoff from step 6
	otus.fasta						the original fasta file of your otu sequences
	otus.above.98.fasta				the output file with fasta sequences at or above your cutoff
	otus.below.98.fasta				the output file with fasta sequences below your cutoff
	
__________________________________________________________________________________________

8. assign taxonomy (mothur)

The classify.seqs() command in mothur classifies sequences using a specified algorithm 
and a provided taxonomy database.  I use the default algorithm (wang with kmer size 8), 
and ask it to show bootstrap values. The output file is a list of sequence ID's next to
their assigned taxonomy.

Full Two Commands (type in terminal):

mothur "#classify.seqs(fasta=otus.above.98.fasta, template=custom.fasta,  taxonomy=custom.taxonomy, method=wang, probs=T, processors=2)"
mothur "#classify.seqs(fasta=otus.below.98.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"

What the first and last commands do:
	~/mothur/mothur		this is the path to the mothur program installed on your computer.
						~/mothur/mothur is the default place to instal it.
						You must open mothur to use the mothur command classify.seqs().
						When in the mothur program " mothur > " appears instead of $
	quit()				exits the mothur program and returns you back to bash in the terminal.

What the filenames are:
	otus.above.98.fasta		this is the fasta file containing only seqIDs >= your cutoff, from step 6
	otus.below.98.fasta		this is the fasta file containing only seqIDs < your cutoff, from step 6
	custom.fasta			this is the fasta file for your small custom taxonomy database (ie freshwater) 
	general.fasta			this is the fasta file for your large general taxonomy database (ie green genes) 
	custom.taxonomy			this is the .taxonomy file for your small custom taxonomy database (ie freshwater)
	general.taxonomy		this is the .taxonomy file for your large general taxonomy database (ie freshwater)

What each flag does:	
	fasta=		path to the .fasta file you want classified
	template=	path to the .fasta file of the taxonomy database
	taxonomy=	path to the taxonomy file of the taxonomy database
	method=		algorithm for assigning taxonomy. default is wang.
	probs=		T or F, show the bootstrap probabilities or not?
	cutoff=		minimum bootstrap value for getting a name instead of unclassified
				typically minimum is 60%
				note: the default is no cutoff, full reporting.  I have an R script that
				let's you apply a bootstrap cutoff after the fact if you want to see everything 1st
	processors=	the number of processors on your computer to run it on
				note: this did not work on my mac, still ran on only 1 core.

What the output files are (note you have no control over the name extensions added):
	otus.above.98.custom.wang.taxonomy
	otus.above.98.custom.wang.tax.summary
	otus.below.98.general.wang.taxonomy
	otus.below.98.general.wang.tax.summary
	
NOTE: these bootstrap percent confidence values are NOT the confidence that the taxonomy 
assignment is *correct*, just that it is *repeatable* in that database.  This is another 
paremeter that we could explore changing more in the future.  It likely should be different
in the different databases also because of the different database sizes.  I left cutoff out
in this command so that you can explore the different results of it later, in steps 13-14.


__________________________________________________________________________________________

9. combine taxonomy files (terminal)

Concatenate the two taxonomy files to create one complete one.  You can very simply just 
combine them because there are no duplicate sequences between them.  The cat command in bash
concatenates two files into one.  You also choose your final file name here.

Full Command (type in terminal):

cat otus.above.98.custom.wang.taxonomy otus.below.98.general.wang.taxonomy > otus.98.taxonomy

Command syntax:
	cat file1 file2 > file3		means "combine file1 and file2 into file 3"
								
What the filenames are:
	otus.above.98.custom.wang.taxonomy		the taxonomy file for sequences classified with custom database
	otus.below.98.general.wang.taxonomy		the taxonomy file for sequences classified with general database
	otus.taxonomy							the name you choose for the output complete taxonomy file for all
											your sequences.


__________________________________________________________________________________________

Steps 10-14 are an optional check.
__________________________________________________________________________________________

10. assign taxonomy with general database only (mothur, bash)

Get a large, general database classification of your otus.fasta file to compare too.  
Green Genes, our general database choice, is a huge database (1,262,986 sequences), so the 
taxonomy assignment clustering algorithm is likely to only settle on a given taxonomic 
assignment if it is unambiguously correct.  Therefore, we trust the upper level Green Genes
assignments more than our custom database, even though we trust the lower level taxonomic
assignments using our custom database more.

So in this step you assign taxonomy with the general database using mothur, and then
rename the output file something easy to work with using bash.

Full Two Commands (type in terminal):

mothur "#classify.seqs(fasta=otus.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
cat otus.general.wang.taxonomy > otus.general.taxonomy

What the commands do:
	See step 8 for a detailed explanation of these two commands and their arguments.

What the filenames are:
	otus.fasta					the original fasta file of your OTU sequences
	general.fasta				the fasta file of the large, general database
	general.taxonomy			the taxonomy file of the large, general database
	otus.general.wang.taxonomy	the taxonomy of your OTUs assigned by the general database
								this is the default name created by mothur
	otus.general.taxonomy		the otus.general.wang.taxonomy file renamed


__________________________________________________________________________________________

11. assign taxonomy to custom database with general database (mothur, bash)

This allows you to compare your two databases to get an idea of the baseline level of 
disagreement you can expect from their taxonomy classifications.  Also, in step 13 you
will generate a list of these disagreements that you can use to update your custom
database classifications to better match your general database, if desired.  When you 
choose an appropriate pident cutoff the goal is to avoid forcing OTUs into the custom
database, which can be seen when the general database gives a very different 
classification. Knowing the level of disagreement between the databases themselves can
give you an idea of how much disagreement is acceptable.

Full Two Commands (Type in Terminal):

mothur "#classify.seqs(fasta=custom.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
cat custom.general.wang.taxonomy custom.general.taxonomy


What the commands do:
	See step 8 for a detailed explanation of these two commands and their arguments.

What the filenames are:
	custom.fasta					the fasta file of the small, custom database
	general.fasta					the fasta file of the large, general database
	custom.general.wang.taxonomy	the taxonomy of your custom database assigned by the general database
									this is the default name created by mothur
	custom.general.taxonomy			the custom.general.wang.taxonomy file renamed
	
	
__________________________________________________________________________________________

12. reformat taxonomy files (bash)

The R script in step 13 requires semicolon delimited taxonomy files.  The mothur output
.taxonomy files are delimited with both tabs and semicolons.

Reformat both files you will compare:
	the otus.taxonomy file created in step 9
	the otus.general.taxonomy file created in step 10

Find: tab
Replace: semicolon

Full Seven Commands (Type in Terminal):

sed 's/[[:blank:]]/\;/' <otus.98.taxonomy >otus.98.taxonomy.reformatted
mv otus.98.taxonomy.reformatted otus.98.taxonomy
sed 's/[[:blank:]]/\;/' <otus.general.taxonomy >otus.general.taxonomy.reformatted
mv otus.general.taxonomy.reformatted otus.general.taxonomy
sed 's/[[:blank:]]/\;/' <custom.general.taxonomy >custom.general.taxonomy.reformatted
mv custom.general.taxonomy.reformatted custom.general.taxonomy
sed 's/[[:blank:]]/\;/' <custom.taxonomy >custom.custom.taxonomy

Syntax of commands and what each argument does:
	sed 's/find/replace/ <input >output
		sed		is a "stream editor," a function for editing streams of text in the terminal
		's		tells it you are doing a substitution
		find	this is the character string you are finding
		replace	this is what you are replacing it with
		input	this is the file sed searches through, here it is
				otus.taxonomy
				otus.general.taxonomy
		output	this is the file sed creates (note it must have a different name than input)
	
	mv filename1 filename2
		mv		this is a function to move (aka rename) a file from name1 to name2
				simply keeping the edited file the same name  
		

__________________________________________________________________________________________

13. compare taxonomy files (bash, R)

The R script find_classification_disagreements.R  creates a folder containing a file for 
each upper taxonomic level (kingdom, phylum, class, order, lineage) that lists all of the 
classification disagreements at that taxonomic level between the custom + general taxonomy
database workflow and the general only taxonomy database workflow. Note that this only 
compares classifications made in the custom database, it ignores differences between 
classifications that were both made by the general database (which can happen because 
the classification algorithm is stochastic.)

This script also allows the user to choose a bootstrap %confidence cutoff under which all
the lower assignments are unclassified.  The script does not include unclassified names in 
its reporting of disagreements.  This allows you ignore taxonomy assignment conflicts when
you don't trust the assignment anyway, and you can decide what you trust (60% is generally
considered the minimum cutoff you should use.)

Additionally, this script generates a final version of your taxonomy file with the applied 
bootstrap cutoff implemented.  The version made in step 9 contains all the taxonomy assignments,
even ones with very low bootstrap p-values.  This generates a .taxonomy file with the cutoff
applied, so that everything under that cutoff is named "unclassified."  Note that you can 
apply this cutoff in step 8 using the "cutoff = #" flag with the mothur command classify.seqs().
I didn't do it there though to make these analysis steps more flexible. The format of this file
is semicolon delimited, which is slightly different than the mothur output files that are tab 
semicolon deliminited between taxonomy levels but tab delimited between the seqID column and
the taxonomy names.

Note: you must create a new folder to save these results in before running the script.
	include the pident cutoff in your folder name, b/c the file names will not include that.
	(Suggested folder name and creation is below.)

Full Two Commands (type in terminal):

mkdir conflicts_98
Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 85 70
mkdir conflicts_database
Rscript find_classification_disagreements.R custom.custom.taxonomy custom.general.taxonomy NA conflicts_database NA NA 70 database 

Note: you must enter all the arguments in this order.

What the arguments are the first time you source the script:
1.	Rscript									this opens R to accept arguments from the command line
2.	find_classification_disagreements.R		this is the R script you're sourcing
3.	otus.98.taxonomy						this is the path to your otu taxonomy file 
											created using both databases in step 9
4.	otus.general.taxonomy					this is the path to your otu taxonomy file
											created using only the general database in step 10
5.	ids.above.98							this is the path to the file created in step 4 that
											contains all of the sequence IDs above or equal to 
											your pident cutoff
6.	conflicts_98							this is the path to the folder you want the R script
											to save the .csv results files in. You create this
											folder in this step with the mkdir command.
7.	98										this is the pident you're using.
8.	85										this is the p-value cutoff for the custom database
											assigned sequences. This determines if a classification
											is good enough to be named or should be "unclassified." 
9.	70										this is the p-value cutoff for the general database
											assigned sequences. This determines if a classification
											is good enough to be named or should be "unclassified." 
	
What the arguments are the second time you source the script:
1.	Rscript									this opens R to accept arguments from the command line
2.	find_classification_disagreements.R		this is the R script you're sourcing
3.	custom.custom.taxonomy					this is the path to your custom taxonomy database 
											after re-formatting it in step 12.
4.	custom.general.taxonomy					this is the path to your custom taxonomy database
											classified using the general database in step 11.
5.	NA										NA is typed as a placeholder here
6.	conflicts_database						this is the path to the folder you want the R script
											to save the .csv results files in. You create this
											folder in this step with the mkdir command.
7.	NA										NA is typed as a placeholder here
8.	NA										NA is typed as a placeholder here
9.	70										this is the p-value cutoff for the general database
											assignments of the custom database fastas. This 
											determines if a classification is good enough to be
											named or should be "unclassified." 	
10.	database								This flag tells the script you are comparing two
											databases instead of OTU classifications.

What the generated files in your conflicts folders are:
	kingdom_conflicts.csv
	phylum_conflicts.csv
	class_conflicts.csv
	order_conflicts.csv
	lineage_conflicts.csv
	conflicts_summary.csv


__________________________________________________________________________________________

14. choose appropriate pident cutoff (R)

This step generates some plots that you can use to double check that your chosen cutoff is 
appropriate.  The plots are saved into the "plots" folder that you created in step 5.  In
order to examine the cutoff sensitivity, you may want to run steps 4-9 & 12-14 multiple times
with different pident cutoffs.  Note that the slowest step, classify.seqs() in mothur, will
be much faster because the mothur database files are not re-made.

Rscript plot_classification_disagreements.R otus.abund plots conflicts_database conflicts_94 ids.above.94 94 conflicts_96 ids.above.96 96 conflicts_98 ids.above.98 98

What the arguments are:
1.		Rscript									Calls program R in a way that accepts command line arguments
2.		plot_classification_disagreements.R		name of the script you are calling
3.		otus.abund								OTU relative abundance table
4.		plots									path to folder you are saving the plots into.
												note: this folder must already exist. you made it in step 5.
5.		conflicts_database						path to folder containing taxonomy disagreements between
												the custom and the general database.
												You made this folder in step 13.
6.		conflicts_94							path to folder containing taxonomy disagreements between
												this cutom+general workflow and the general database alone.
												You made this folder in step 13.
7.		ids.above.94							path to the file that lists all the seqIDs meeting your
												pident cutoff that were therefore classified with your
												custom databse. You made this file in step 4.
8.		94										pident cutoff used in the previous two arguments
8.		conflicts_96							folder of taxonomy disagreements
9.		ids.above.94							file of custom-classified seqIDs	
10.		96										pident cutoff for previous two arguments
n.		...										additional arguments
												you can have as many pident cutoffs compared as you
												want.  Just keep listing them in this format:
												folder_path ids.file pident folder_path ids.file pident ...

What the generated plots are:
	***choose which ones to export***

__________________________________________________________________________________________

15. generate final taxonomy file (R)

Based on your results from step 14, choose which pident cutoff to use.  Use the same script 
from step 13, except this time specify "final."  This final taxonomy file is different from 
files created in step 9 because it applies your clustering bootstrap pvalue cutoff, calling
everything below that cutoff "unclassified."  

Recall that choosing that cutoff was left out of the mothur command to allow flexibility in
analyzing results.  The "final" argument to this script is left out in step 13 because it takes
longer when it is included.  This is because in finding the classification disagreements, the
script only compares classifications assigned by the custom database, which is a small subset 
of all of the classifications.

Rscript find_classification_disagreements.R otus.98.taxonomy NA ids.above.98 conflicts_98 98 85 70 final


__________________________________________________________________________________________

16. tidy up (bash)

This step tidies up your working directory folder by removing intermediate files you don't 
need anymore and moving remaining files into orgainized folders.
Note: these bash commands only work if you've been using the same names as the workflow.
Note: go through these commands in order.


16.1 remove intermediate files

Full Command (Type in Terminal):

rm custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy

What each of these intermediate files is and why you might want to keep them:
custom.db.*		The blast database files (saves time if you want to re-run blast on the same taxonomy database)
custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree*
				The mothur database files (saves time if you want to re-run classify seqs with the same taxonomy database)
*wang* mothur.*.logfile
				The mothur classify seqs output files (these can be regenerated quickly if you save mothur db files)
otus.custom.blast*
				The blast results (these are quick to regenerate if you have the blast database)
ids*			lists of seqIDs (not needed once you have the fasta files)
rm otus.below*.fasta otus.above*.fasta
				separated fasta files (not needed post-classification.)
otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy
				the classifications at different pident cutoffs and from green genes alone
				note: these files don't have p-value cutoffs applied (i.e. nothing's called unclassified). 
				If you want to save files like these for additional analysis, 
					re-run step 15 to get additional "final" versions.
					re-run step 10 with an additional "cutoff=" flag.

Note: if for some reason you want to keep these files, you can either skip this step
or type in the terminal:

mkdir intermediate
mv custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta intermediate/


16.2 move scripts into scripts folder

Full 2 commands (Type in Terminal):

mkdir scripts
mv *.py *.R *.sh scripts/

Note: I recommend saving all the script versions you used to create your data so you could reproduce it.


16.3 save files used in analyzing your results in analysis folder

Full 2 commands (Type in Terminal):

mkdir analysis/
mv conflicts* plots/ analysis/

Note: You can delete this instead if you're all done analyzing. Instead of the two commands, type:

rm -r conflicts* plots/

16.4 save your actual data files in a folder called data

Full Two commands (Type in Terminal):

mkdir data
mv otus* data/

Note: Yeyy!  This is what you're gonna use to actually do stuff now!!


16.5 save the version of the taxonomy databases you used in a databases folder

Full Two Commands (type in terminal):

mkdir databases
mv *.taxonomy *.fasta databases

Note: I highly recommend you keep these versions of the databases you used so you can reproduce your data.


__________________________________________________________________________________________

~The end~
__________________________________________________________________________________________