---
title: "TaxAss Workflow"
author: "Robin Rohwer"
date: "last updated: July 3, 2020"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
```

TaxAss assigns taxonomy to a fasta file of OTU sequences using both a 
small, custom taxonomy database and a large general database.

Download the scripts from the github repo: https://github.com/McMahonLab/TaxAss  

Please cite TaxAss: [Rohwer RR, Hamilton JJ, Newton RJ, McMahon KD. 2018. TaxAss: Leveraging a Custom Freshwater Database Achieves Fine-Scale Taxonomic Resolution. mSphere 3:e00327-18.](https://msphere.asm.org/content/3/5/e00327-18)


# <span style="color:Red">Quick Directions</span>

The full directions include extra validation steps used in the [paper](https://msphere.asm.org/content/3/5/e00327-18) that you don't need to include to just assign taxonomy to your data, along with a lot of explanation and troubleshooting advice. Here are the basic steps to run TaxAss on your data.  

### <span style="color:Red">Set-up</span>  

* You need mothur, blast, python, and r installed and on your path.  
    (directions & download links in step -1)  

* You need to format your fasta file.  
    ex: not aligned, name ends with .fasta, nothing but seqID in the carrot line    
    (directions and reformatting scripts in step 0)
    
* You need the custom and general taxonomy databases.  
    (The FreshTrain (custom) and silva & greengenes (general) databases are already formatted for you in the `FreshTrain-files` folder. Or if you use something different, follow directions in step 0)

* You need the contents of the `tax-scripts` folder. 

Create an empty folder to be your working directory for TaxAss.  
Add the tax-scripts contents, your fasta file, and the database files.  

### <span style="color:Red">TaxAss</span>  

Navigate to the Taxass working directory in the terminal. Then run a batch script to run all the TaxAss scripts for you.  
(steps 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 15)  

```{bash, eval=F}
./RunSteps_quickie.sh otus custom general 98 80 80 2
```  
Input | Despription  
------|----------------------------------------------------------------------------
`otus`        | The name of your fasta file, without the .fasta extension.<br>For example, if my data file is called `Lake_OTUs.fasta` I would write `Lake_OTUs`  
`custom`      | The name of the custom database, without file extensions.<br>For example, if I am using `FreshTrain15Jun2020.taxonomy` and `FreshTrain15Jun2020.fasta` I would write `FreshTrain15Jun2020`  
`general`     | The name of the general database, without file extensions.<br>For example, if I am using `silva_nr_v138.taxonomy` and `silva_nr_v138.fasta` I would write `silva_nr_v138`  
`98`          | The blast percent identity cutoff used to decide which database to classify each OTU in.<br>For example, if an OTU has >98 percent identity to any reference in the FreshTrain, it will be classified with the FreshTrain database. We recommend using 98 with unique or error-corrected sequences. If you use clustered OTUs, we recommend choosing the same or lower similarity used for clustering (and using 98 or 99 to cluster!)  
`80`          | The bootstrap confidence used in the custom classification.<br>For example, this will label an OTU "unclassified" if the Wang classifier implemented in mothur does not assign the same classification 80% of the time. 80 is mothur's default value.   
`80`          | Same as above, but this is the bootstrap confidence used in the general classification.  
`2`           | The number of processors to use in the mothur commands.  

### <span style="color:Red">Clean-Up</span>  

TaxAss has another script that deletes all the intermediate files you'll never need again and sorts the other files into  
4 folders: `data` `databases` `scripts` `analysis`

```{bash, eval=F}
./RunStep_16.sh otus custom general
```

Where `otus` `custom` and `general` are the same names you used in `RunSteps_quickie.sh` above.  
<br>
<span style="color:Red">~done!~</span>  
<br>
<br>
___________

# <span style="color:SteelBlue">List of Steps</span>

Below is a list of all the commands in each step, including the optional ones:  
````
-1. Download/Install 
  BLAST+
  R
  mothur
  (your computer already has python)
  taxonomy databases

0. format files (textwrangler/bash/R)
	depends on your starting file formats
	for fasta files:
		Rscript reformat_fasta.R aligned.fasta created.fasta format.ids replace.U
	for taxonomy files:
		Rscript reformat_taxonomy_nomenclature.R mothur.formatted.tax new.tax.file file.type
	for mothur count_table files:
		sed 's/-//g' <aligned.fasta >otus.fasta
		sed 's/-//g' <names-with-dashed.count_table >otus.count_table
		Rscript reformat_mothur_OTU_tables.R StupidLongMothurName.count_table count_table otus.abund
	for dada2 seqtab_nochim as OTU table:
		Rscript reformat_dada2_seqtabs.R seqtab_nochim.rds otus.fasta otus.abund otus.count
		
1. make BLAST database file (blast)
	makeblastdb -dbtype nucl -in custom.fasta -input_type fasta -parse_seqids -out custom.db

2. run BLAST (blast)
	blastn -query otus.fasta -task megablast -db custom.db -out otus.custom.blast -outfmt 11 -max_target_seqs 5

3. reformat blast results (blast)
	blast_formatter -archive otus.custom.blast -outfmt "6 qseqid pident length qlen qstart qend" -out otus.custom.blast.table

4. recalculate pident (R)
	Rscript calc_full_length_pident.R otus.custom.blast.table otus.custom.blast.table.modified

5. filter BLAST results (R)
	Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.above.98 98 TRUE 
	Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.below.98 98 FALSE

6. check BLAST settings (R)
	Rscript plot_blast_hit_stats.R otus.custom.blast.table.modified 98 plots

7. recover sequence IDs left out of blast (python, bash)
	python find_seqIDs_blast_removed.py otus.fasta otus.custom.blast.table.modified ids.missing
	cat ids.below.98 ids.missing > ids.below.98.all
	
8. create fasta files of desired sequence IDs (python)
	python create_fastas_given_seqIDs.py ids.above.98 otus.fasta otus.above.98.fasta
	python create_fastas_given_seqIDs.py ids.below.98.all otus.fasta otus.below.98.fasta

9. assign taxonomy (mothur)
	mothur "#classify.seqs(fasta=otus.above.98.fasta, template=custom.fasta,  taxonomy=custom.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
	mothur "#classify.seqs(fasta=otus.below.98.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"

10. combine taxonomy files (bash)
	cat otus.above.98.custom.wang.taxonomy otus.below.98.general.wang.taxonomy > otus.98.taxonomy

11. OPTIONAL- assign taxonomy with general database only (mothur, bash)
	(needed for validation steps 13, 14, 15.5)
	mothur "#classify.seqs(fasta=otus.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
	cat otus.general.wang.taxonomy > otus.general.taxonomy

11.5 OPTIONAL- assign taxonomy to custom database with general database (mothur, bash)
	(feeds into Database_Improvement_Workflow)
	mothur "#classify.seqs(fasta=custom.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
	cat custom.general.wang.taxonomy custom.general.taxonomy

12. reformat taxonomy files (bash)
	sed 's/[[:blank:]]/\;/' <otus.98.taxonomy >otus.98.taxonomy.reformatted
	mv otus.98.taxonomy.reformatted otus.98.taxonomy
	OPTIONAL- need if did step 11
	sed 's/[[:blank:]]/\;/' <otus.general.taxonomy >otus.general.taxonomy.reformatted
	mv otus.general.taxonomy.reformatted otus.general.taxonomy
	
13. OPTIONAL- compare taxonomy files (R)
	(needed for validation steps 11, 14, 15.5)
	mkdir conflicts_98
	Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 80 80
	
14. OPTIONAL: choose appropriate pident cutoff (R)
	(needed for validation steps 11, 13, 15.5)
	note: you have to repeat steps 5, 7-10, & 12-13 with multiple pident cutoffs to do this step
	Rscript plot_classification_disagreements.R otus.abund plots regular NA NA conflicts_94 ids.above.94 94 conflicts_96 ids.above.96 96 conflicts_98 ids.above.98 98

15. generate final taxonomy file (R)
	OPTIONAL- if did all the validation steps 11, 13, 14, 15.5a
	Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 85 70 final
	If doing only "quickie" steps.:
	Rscript find_classification_disagreements.R otus.98.taxonomy quickie ids.above.98 conflicts_98 98 85 70 final
	
15.5 OPTIONAL- plot benefits of using this workflow (R, mothur, bash)
	a. Improvement over general database only:
		Rscript plot_classification_improvement.R final.taxonomy.pvalues final.general.pvalues total.reads.per.seqID.csv plots final.taxonomy.names final.general.names
	b. Improvement over custom database only:
		mothur "#classify.seqs(fasta=otus.fasta, template=custom.fasta, taxonomy=custom.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
		cat otus.custom.wang.taxonomy > otus.custom.taxonomy
		sed 's/[[:blank:]]/\;/' <otus.custom.taxonomy >otus.custom.taxonomy.reformatted
		mv otus.custom.taxonomy.reformatted otus.custom.taxonomy
		mkdir conflicts_forcing
		Rscript find_classification_disagreements.R otus.custom.taxonomy otus.98.85.70.taxonomy ids.above.98 conflicts_forcing NA 85 70 forcing
		Rscript plot_classification_disagreements.R otus.abund plots conflicts_forcing otus.custom.85.taxonomy otus.98.85.70.taxonomy

16. tidy up (bash)
	rm custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy otus.custom.taxonomy otus.custom.[0-9]* custom.general* *pvalues total* final*names
    mkdir scripts ; mv *.py *.R *.sh *.md *.Rmd *.html scripts
    mkdir analysis ; mv conflicts* *.txt plots analysis
    mkdir data ; mv otus* data
    mkdir databases ; mv *.taxonomy *.fasta databases

Batch Scripts:

Full TaxAss:
  a. Run a bunch of pidents
    ./RunSteps_1-14.sh otus custom general "100 99 98 97 96 95" 80 80 2
  b. create final taxonomy at chosen pident 
    ./RunStep_15.sh otus custom general 98 80 80 2
  c. clean up after everything worked
    ./RunStep_16.sh otus custom general

As few steps as possible (choose pident without comparing):
  a. Run 1 pident with no checks
    ./RunSteps_quickie.sh otus custom general 98 80 80 2
  b. Clean-up folder
    ./RunStep_16.sh otus custom general
  
````

__________________________________________________________________________________________

# <span style="color:SteelBlue">-1. download/install</span>

### Programs Needed:  

Program       | Version             | Source                  | Specific Link
--------------|---------------------|-------------------------|------------------------------------------  
mothur        | v.1.44.1          | www.mothur.org          | https://github.com/mothur/mothur/releases  
BLAST         | 2.10.0              | ncbi.nlm.nih.gov        | ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/  
TaxAss        | master branch       | `tax-scripts` folder    | https://github.com/McMahonLab/TaxAss <br> You don't need your own github account; you can click the green download button on the top right of the main page (do have to download all folders unfortunately)  
python        | 2.7 or 3.7          | your computer already has this | don't need anything extra
R             | 3 or 4              | cran.r-project.org      | https://cran.r-project.org/


You want mothur and BLAST on your "path" (that means if you type them, your computer recognizes it as a program and runs it).
BLAST does that automatically if you use the `.dmg` file to install it, but mothur does not. 
First make sure mothur is downloaded to your home directory- should open if you type `~/mothur/mothur`.   

**To add mothur to your path:**   
```
# open terminal window
~ $ open .bash_profile

# or if this file doesn't exist already:
~ $ touch .bash_profile
~ $ open .bash_profile

# add this line to the .bash_profile document
export PATH=~/mothur:$PATH
```
Now you can open the mothur program just by typing `mothur` from any location. (after restarting terminal)

### Database options:

Database      | Version | File Name          | Download From
--------------|---------|--------------------|-------------------------  
FreshTrain    | 30Apr2018<br>or<br>25Jan2018 | FreshTrain30Apr2018SILVAv132.zip<br>FreshTrain30Apr2018SILVAv128.zip<br>FreshTrain25Jan2018Greengenes13_5.zip | https://github.com/McMahonLab/TaxAss/FreshTrain-files
Greengenes    | Aug 2013  | "greengenes reference taxonomy" | https://www.mothur.org/wiki/Greengenes-formatted_databases
Silva         | v.132 <br> v.128 <br> v.138 | "Full length sequences and taxonomy references" | https://www.mothur.org/wiki/Silva_reference_files

**Paired pre-formatted general databases are included in the FreshTrain zip files now.** Save yourself 20 min of unaligning :)  

(Note that if you're a non-academic or commercial user you have to pay to use silva releases earlier than v.138.)

__________________________________________________________________________________________

# <span style="color:SteelBlue">0. format files</span> {.tabset}

## Files Needed

#### <span style="color:SteelBlue">Use the tabs (above) for details on formatting each file type.</span>

These are the files you supply as input into the workflow:  

File                | Description
--------------------|------------------------------------------------------------------
	otus.fasta			  | fasta sequences for each of your OTUs <br> (OTUs can be clustered, error corrected, or unique sequences)
	otus.abund			  | relative abundance of each OTU (i.e. the OTU table)<br>(Optional- don't need if following "quickie" procedure)
	general.fasta		  | fasta sequences in your large, general comrpehensive taxonomy database
	general.taxonomy	| taxonomy names in your large, general comprehensive taxonomy database
	custom.fasta		  | fasta sequences in your small, ecosystem-specific taxonomy database
	custom.taxonomy		| taxonomy names in your small, ecosystem-specific taxonomy database

**Move everything into the same folder, and make that your working directory.**  
To make your life easier, create a new folder that contains the tax-scripts, the database and data files listed above, and nothing else. Then navigate to this folder in the terminal to make it your present working directory (`pwd`). Also, rename your files to match the above names so that you can copy and paste commands from this workflow.

_____________________________________________

## OTU files  

How to format `otus.fasta` and `otus.abund`, including specific directions for converting mothur and dada2 file formats.  
(you don't need `otus.abund` if you are taking the "quickie" route and not running the validation steps.)
<br><br>

___________

### Format your file names  

If you are using filenames other than the default `otus.fasta` and `otus.abund` the filenames: 

- **must contain exact extensions `.fasta` and `.abund`**  
			 	This is necessary for running the batch script, otherwise it will not be able to parse the names.  
- **cannot contain any white space**  
			 	No spaces in file names, use CamelCase, underscores, or periods.
  

___________

<br>

### Format your sequence ID's  

The seqIDs in your otus.fasta and otus.abund files must follow these requirements:

- **cannot contain any whitespace**  
			 	BLAST will call some parts the seqID and some parts comments if they're separated.
			 	Having BLAST seqIDs that don't match the full `>comment` line of the fasta file will 
		 	 	throw off the python script that creates fasta files for the chosen seqIDs in step 8.
		 	 	Having any spaces will also throw off the R script that checks blast hit numbers.
- **cannot contain semicolons**   
			 	The taxonomy file format produced by mothur is semicolon delimited, so semicolons in
			 	file names will throw off all R scripts by adding an extra column.
- **must match between the otus.fasta file and the otus.abund file**  
			 	(though consistent ordering is not necessary.)

___________

<br>

### Format `otus.fasta`   

These should be in fasta format: 

- carrot before the seqID
- a new line separating seqID from sequence
- sequence can be one line or multiple lines 
- OTU sequences should not be aligned (taxonomy reference can be aligned)

Example of correct format:
```
>seqID
TACGTAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAG
>seqID
TACGTAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAG
```

Example of aligned format:  
```
>seqID
........GAG-G-A-A--TA-TT--GG-T-C----AA-T-G-G--GC-----GC-A--A---G-C-C-T-G-A-A-C-C-A---GC-C--A--T-GCC-G-A-G-T------G-C-A--G--GA-----------------------------T-G--A--C--G-G-TC----C---TA-TG-----G-A-T-----T-G-T-A---AA-C-T-GC--------------------TT-TT-G-T--A-CAG----G--A-A--G---AA-ACAC-T---C-C-C--T---------------------C----------------------------GT---------------------------G------------------------A-GGG-A-GC-T-T-G-A-C-G-----G-T---A-C-TG--------T-A-A-G----..........
```  
<br>
**Remove the hyphens, dots, and all text after the first blank in a seqID line with `reformat_fasta.R`:**  

Full Command (Type in Terminal):
```{bash, eval=F}
Rscript reformat_fasta.R aligned.fasta otus.fasta check.seqids
```  

command   | description
----------|----------------------------------------------
`reformat_fasta.R`     | Name of script being run.  
`aligned.fasta` 		  | Name of your fasta file that needs to be unaligned or have seqIDs edited. 
`otus.fasta`		|	Name of the file this script creates. `otus.fasta` matches the names used in this workflow.
`check.seqids` 		  | Do check the seqID names and if there are any white spaces (tabs or spaces), remove the white space and anything after it on the line. If there are no white spaces it won't change anything. If you DON'T want it to edit your seqIDs, then leave this argument blank  

___________

<br>

### Format `otus.abund` 

NOTE: you don't need this file if you are taking the "quickie" route and not running the validation steps. 
_i.e._ you're choosing a pident from the start, and just making the taxonomy table with no other checks.

**This is the table of relative abundances for each OTU in each sample, aka your OTU table:** 

- **relative abundance not raw counts**  
	 That means you could either have subsampled during QC, or have divided all abundances
	 in a given sample by the total reads in that samples.  In other words, it must be 
	 relativized by sample so that each sample has the same total reads. This is important 
	 for the plot in step 14 that helps you choose an appropriate pident cutoff.
- **tab delimited**  
- **seqIDs in 1st column, abundances in rest of columns** 
- **with headers (column names), but no row names**  
- **no "totals" row/column**  
   (as might have been added by mother)
- **numbers only for all abundance values**  
   Note that if you had a sample that failed sequencing, there might be no reads left in it after QC. This sample should be removed before TaxAss or normalizing it could cause a `NaN` not-a-number value.

```
colname	colname		colname		colname		colname
seqID	Abundance	Abundance	Abundance	Abundance
seqID	Abundance	Abundance	Abundance	Abundance
seqID	Abundance	Abundance	Abundance	Abundance
```

___________

<br>

### Get `otus.fasta` and `otus.abund` from a dada2 `seqtab_nochim` 

If you are using dada2 within RStudio, save the `seqtab_nochim` object as an R data structure:  
```{R, eval=F}
saveRDS(object = seqtab_nochim, file = "seqtab_nochim.rds")
```

You can convert this into both the otus.fasta and the otus.abund files this way: 

Full Command (type in terminal):
```{bash, eval=F}
Rscript reformat_dada2_seqtabs.R seqtab_nochim.rds otus.fasta otus.abund otus.count
```

command argument                   | description
-----------------------------------|----------------------------------------------
`Rscript`					                 | way to source an R script with arguments  
`reformat_dada2_seqtabs.R`         | Name of R script to run
`seqtab_nochim.rds`                | saved dada2 object file
`otus.fasta`                       | name of created fasta file to feed into TaxAss
`otus.abund`							         | name of created relative abundance table to feed into TaxAss<br> note: this has been converted to relatve abundance (normalized by sample so that abundance values in each sample sum to 100)
`otus.count`                       | name of created file that saves the total reads per sample. This is not used in TaxAss, but saves the information you would need to un-normalize your abundance data so that it's not lost.  

___________
		
<br>
		
### Get `otus.abund` from a mothur `.count_table`

If you used mothur for QC and are proceeding with unique sequences, as in the TaxAss paper, you can reformat the outs.count_table file this way:  
		
Full Command (type in terminal):
```{bash, eval=F}
Rscript reformat_mothur_OTU_tables.R StupidLongMothurName.count_table count_table otus.abund
```

command argument                   | description
-----------------------------------|----------------------------------------------
`Rscript`					                 | way to source an R script with arguments  
`reformat_mothur_OTU_tables.R`     | Name of R script to run
`StupidLongMothurName.count_table` | name of the mothur file you're starting with
`count_table`                      | type of mothur file, as specified by it's extension. <br> ideally this will include shared or the qiime version at some point...
`otus.abund`							         | name of the OTU table you feed into this workflow
		
More notes on the mothur file types:  

* `.count_table` : use if you are not clustering sequences, just cleaning sequencing errors
* `.shared` : use if you clustered sequences  
  In other words, whatever your last OTU-esque table is prior to assigning taxonomy.
	Note that the .abund mothur file is a non-table-y space-saving format that you can't use here.
	Sorry for the confusing file extension choice.

<br>

#### <span style="color:SteelBlue"> Use the tabs at the top of this section to find directions for the database files! </span>  

_____________________________________________

_____________________________________________

## Database files

How to format the `general.taxonomy` and `general.fasta` files.  
<br>
**NOTE: I have a pre-formatted version of all paired general databases in the zipped FreshTrain files folder.**  

If you want to use databases that are not already paired, you will want to first follow the Directions in `arb-scripts/Directions_Create_New_FreshTrain_Release.html` to make custom and general versions compatible.  Mostly, this makes sure that coarse-level name match. For example, one should not have phylum Actinobacteria while the other has phylum Actinobacteriota.  Contact me and I will help you with this! (robin.rohwer@gmail.com)  

___________

### Format your file names  

If you are using filenames other than the default `general.fasta`, `general.taxonomy` and `custom.fasta`, `custom.taxonomy` the filenames: 

- **must contain exact extensions `.fasta` and `.taxonomy`**  
			 	This is necessary for running the batch script, otherwise it will not be able to parse the names.  
- **cannot contain any white space**  
			 	No spaces in file names, use CamelCase or underscores
- **cannot contain periods except for before the file extensions**  
			 	This is necessary for running the batch script, otherwise mothur will truncate the name that comes before the period in `classify.seqs()` and the file names will not match the expected names in the batch scripts.  

___________

<br>

### Format `general.fasta`    

The silva reference downloaded from mothur is aligned (greengenes from mothur is not). Using this file directly for taxonomy assignment works just fine, but unaligning reduces the file size (for v132) from **10.68 GB to 318 MB.** _dang!_ It takes 10-20 minutes to run this script to remove hyphens and semicolons, and it saves about the same time later on during taxonomy assignment. None of mothur's intermediate files change sizes though. This script can also strip additional text from the seqID line (everything following a white space) if that is there. The directions for formatting otus.fasta have some more directions for this script.  

Full Command (Type in Terminal):
```{bash, eval=F}
Rscript reformat_fasta.R aligned.fasta general.fasta 
```  

command   | description
----------|----------------------------------------------
`reformat_fasta.R`     | Name of script being run.  
`aligned.fasta` 		  | Name of your fasta file that needs to be unaligned or have seqIDs edited. 
`general.fasta`		|	Name of the file this script creates. `general.fasta` matches the names used in this workflow.
`          ` 		  | No need to edit the seqID names, unless new versions of silva add white space to them, so leave this argument blank. If you do need to remove additional crap from the seqID line, just type `seq.id` here.     


___________

<br>

### Format `general.taxonomy` 

Downloading from mothur, you shouldn't need to worry about reformatting. 
But if you are using a different version, it must be compatible with mothur:  

- no whitespace except for the tab between seqID and taxonomy
- taxonomy level names separated by semicolons
- must have a semicolon at the end of each line, too!

Example of correct format:  
```		
seqID	kingdom;phylum;class;order;family;genus;species;
```  
<br>

**Format nomenclature to avoid:**  

* inconsistent nomenclature for sequences that don't have names  
* identical names at different taxon-levels 
* identical names within a taxon level that have different parent names (non-monophyletic)

Inconsistent "unclassified" names will mess up choosing the pident and looking at improvement, because things can look like they're classified when actually they're classified to "unknown.family". The identical names within and between levels just mess up my own processing scripts after taxass, for example when I try to group by taxonomy.  You can fix these problems with the script `reformat_taxonomy_nomenclature.R`.  

Full Command (type in terminal):

```{bash, eval=F}
Rscript reformat_taxonomy_nomenclature.R silva.nr_v132.tax general.taxonomy
```

command argument   | description
-------------------|----------------------------------------------
`silva.nr_v132.tax`  | input file. the mothur-formatted silva taxonomy with inconsistent names.
`general.taxonomy`   | created silva taxonomy with consistent unclassified names that is ready-to-taxass!  

Comments in the script are very detailed as to examples of the changes.

Any of these words can describe references without a name:    

* unnamed  
* unknown  
* uncultured  
* uncertain  
* Incertae_Sedis  
* unclassified
* ParentName_ge  (or _ph _cl _or _fa)  
* blank  
* blank with greengenes level ID (k__ p__ c__ etc)

And this script changes them to all be: 

* unnamed.ClosestKnownParentName

This script additionally makes all taxonomy names unique. For only those names that are duplicated, a capitol letter indicating the taxon-level is added to the end of the name, separated by a period. For example, "Actinobacteria" is a phylum and a class in Silva132, so it becomes "Actinobacteria.P" and "Actinobacteria.C" .  

The capitol letters "K P C O F G S" are used for silva/greengenes-derived names, and the lowercase letters "l c t" are used for FreshTrain-derived lineage clade tribe names. This way you know that a capitol C mean class and a lowercase c means clade.     

<br>
<br>


__________________________________________________________________________________________

# <span style="color:SteelBlue">1. make BLAST database</span>

Use the command `makeblastdb` to create a blast database out of the FW taxonomy fasta files.  
Need to create a database because:  

1. BLAST will run faster
2. Having a database is necessary for some of the output formats

Full Command (type in terminal):
```
makeblastdb -dbtype nucl -in custom.fasta -input_type fasta -parse_seqids -out custom.db
```

command argument     | description
---------------------|----------------------------------------------
`-dbtype nucl`    	 | a required argument, says the database input file is nucleic acids (nucl)
`-in custom.fasta`	 | specify path of the input file that it makes the database out of. <br>this is the path to the small custom taxonomy file you want to use<br>(i.e. the freshwater taxonomy database fasta file)<br>note: if the file path has spaces in it, it needs to be `' "/path/double quoted" '`  
`-input_type fasta`	 | specifies the input file is a fasta file (that's the default value too)  
`-parse_seqids`		   | this tells it to include information in the database that will later allow you to pull sequences back out of it. This is necessary for using blast_formatter later.
`-out custom.db`		 | specify path of the database files this command creats. BLAST makes 6 files with different extensions, but they all start with this.  the default is your `-in` file name with those extensions, but it's less confusing to add `.db` so you can easily identify what each file is.  

These 5 files are created:  
`custom.db.nhr`  
`custom.db.nog`  
`custom.db.nsd`  
`custom.db.nsi`  
`custom.db.nsq`  
(but later when you tell BLAST which database file to use you just say `custom.db` and it figures the rest out)

__________________________________________________________________________________________

# <span style="color:SteelBlue">2. run BLAST</span>

Use the command `blastn` to run a megablast that returns the best hit in the taxonomy database (subject)
for each of your OTU sequences (queries). Megablast is optimized for finding very similar matches with
sequences longer than 30 bp.  This workflow created with ~100-400 bp sequences and may need to be re-optimized
for sequences of different lengths.  You check if settings are appropriate in step 6.  

Full Command (type in terminal):
```
blastn -query otus.fasta -task megablast -db custom.db -out otus.custom.blast -outfmt 11 -max_target_seqs 5
```

command argument         | description
-------------------------|----------------------------------------------
`-query otus.fasta`      | specify path of query file: `otus.fasta`.<br>This is the fasta file of your OTU sequences you want classified that you reformatted in step 0.
`-task megablast` 	     | this is already optimized by smart BLAST people for high similarity hits.<br>It is also the blastn default task. for more info see: http://www.ncbi.nlm.nih.gov/Class/MLACourse/Modules/BLAST/nucleotide_blast.html
`-db custom.db` 		     | the name of the blast database created in step 1 (without the additional file extensions)<br>This database is made from your subject sequences: the small, custom taxonomy database
`-out otus.custom.blast` | specify path of the blast output file (this is the file you're creating). Its format is unreadable by you, but it's the detailed BLAST format that blast_formatter accepts.<br>The filename here describes `query.subject.blast`  
`-outfmt 11` 				     | need this format in order to use blast_formatter command
`-max_target_seqs 5`		 | only keep the best 5 hits for each query sequence.<br>you will compare how good these are to check if BLAST settings are appropriate in step 6. you can choose more or less target seqs if you want to, it doesn't have a huge impact on speed.  

__________________________________________________________________________________________

# <span style="color:SteelBlue">3. reformat BLAST results</span>

The `blast_formatter` function in blast takes the outformat 11 file and reformats it to any other
possible format.  Here we reformat to a custom table format to feed into the R script that pulls out
matching and nonmatching sequence IDs.  

If you're curious, using blast_formatter you can look at your blast results from the previous step any way you'd like!
Just keep in mind, things like "length" have different definitions in different output formats (yeah. really.), 
so pay careful attention if you try to re-do calculations in the next step on your own. There's a really clear description of this in the TaxAss paper's supplemental document 1.  

Full Command (type in terminal):
```
blast_formatter -archive otus.custom.blast -outfmt "6 qseqid pident length qlen qstart qend" -out otus.custom.blast.table
```

command argument                                      | description
------------------------------------------------------|----------------------------------------------
`-archive otus.custom.blast` 	                        | Specify path to the blast result file you are reformatting. This was generated in step 2, it is in the ASN.1 blast file format.
`-outfmt "6 qseqid pident length qlen qstart qend"`	  | 6 is a tabular format without headers or other info btwn rows of data, the rest specifies what goes in each tab-delimited column:<br>**1** `qseqid`: query (OTU) sequence ID<br>**2** `pident`: percent identity (# of matches / # "columns" in the HSP)<br>**3** `length`: length of alignment<br>**4** `qlen`: full length of query sequence<br>**5** `qstart`: index of beginning of alignment on query sequence<br>**6** `qend`: index of end of alignment on query sequence  
`-out otus.custom.blast.table`  	                    | Specify path to the output file with above formatting.
__________________________________________________________________________________________

# <span style="color:SteelBlue">4. recalculate pident</span>

The `calc_full_length_pident.R` script takes the formatted blast file and calculates a 
"full length" pident value that corrects the pident value for the entire length of the query.
BLAST returns the "highest scoring pair", which is weighted by both similarity and length.
However we are trying to compare the entire OTU sequence, not just a section of it that 
matches really well.  I could not find any command that forces blast use the entire query 
sequence, so this is the workaround. This "full length" pident is a conservative, worst case 
scenario that assumes any edge gaps are mismatches.  

Calculation:  
	"full length pident" = pident * length / (length - (qend - qstart) + qlen)  

This script performs those calculations, and then checks which of the top 5 reported BLAST hits had
the best corrected, full length pident.  It returns a similar, tab delimited output file that 
includes the corrected full length pident and which BLAST hit number had the best corrected pident.  

NOTE: If you are curious about this equation/calculation, there's a REALLY DETAILED explanation in the TaxAss paper's
[Supplemental Document 2](https://github.com/McMahonLab/TaxAss/blob/master/figure-scripts/text_S1_BLAST_example_calc.pdf). It lists what each BLAST term refers to, derives the equation using those terms, and then 
provides an example alignment to show examples of all the calculations. And it's color coded.  

Full Command (type in terminal):
```
Rscript calc_full_length_pident.R otus.custom.blast.table otus.custom.blast.table.modified
```

command argument                   | description
-----------------------------------|----------------------------------------------
`Rscript`								           | sources the R script using the arguments supplied after it in the terminal.
`calc_full_length_pident.R`        | the R script.
`otus.custom.blast.table`          | the formatted blast output from step 3
`otus.custom.blast.table.modified` | the output file containing the modified BLAST hit table, used in step 5. It contains tab delimited columns without column names. They are:<br>qseqid, pident, length, qlen, q.align, true.pids, hit.num.best.ids

__________________________________________________________________________________________

# <span style="color:SteelBlue">5. filter BLAST results</span>

This R script, `filter_seqIDs_by_pident.R`, is run twice. First to generate the sequence ID's 
above/equal to the user specified "full length pident" cutoff.  Those sequence IDs are 
destined for taxonomy assignment in the small custom database.  Second it is run to generate 
the sequence ID's below the "full length pident" cutoff, which are destined for taxonomy 
assignment in the large general database.  

Full Two Commands (type in terminal):
```
Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.above.98 98 TRUE 
Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.below.98 98 FALSE
```

command argument                   | description
-----------------------------------|----------------------------------------------
`Rscript`								           | Sources the R script using the arguments supplied after it in the terminal.
`filter_seqIDs_by_pident.R`			   | The R script.  
`otus.custom.blast.table.modified` | the BLAST table with recalculated, full length pident values created in step 4.
`ids.above.98` 						         | the output file containing seqIDs at or above your cutoff value, used in step 8.
`ids.below.98`						         | the output file containing seqIDs below your cutoff value, used in step 7 & 8.
`98`									             | the full length pident cutoff you are using to decide which sequences belong in which taxonomy database classification
`TRUE`								             | return seqID's >= cutoff
`FALSE`								             | return seqID's < cutoff

Format of the output files `ids.*.98` are \n delimited seqIDs, no header:
```
seqID01
seqID03
seqID04
```
__________________________________________________________________________________________

# <span style="color:SteelBlue">6. check BLAST settings</span>


There is no way to force BLAST to return only full-length hits, it will always return the 
best "High Scoring Pair (HSP)" it finds, based on it's scoring that weights both the quality
and length of the hit.  However, for this use we are only interested in full length matches
because the entire OTU sequences are matched to the reference 16S sequences when assigning 
taxonomy.

High pident short HSPs will be converted to low pident "full length" HSPs because all missing
basepairs are considered a mismatch by my conservative calculation in step 4.  Therefore, some high 
pident short HSPs are reported by BLAST instead of lower pident long HSPs. The true full length
pident could have been higher than my conservative calculation from the BLAST pident that assumes
all un-reported basepairs are mismatches.  If this is happening, then you might not include seqIDs
in your custom classification that met your cutoff.  However, the pident cutoff for taxonomy assignment 
using 16S sequences is pretty high, so while it's likely that some of the short BLAST HSPs
may have longer HSPs with better full-length pidents, it's less likely that any of those better, 
"true" pidents would be good enough to meet your pident criteria. 

The likelihood of incorrect results because of BLAST choosing HSPs that are not full length probably increases
as the length of your OTU sequences increases.  This step tries to check if this might
be a problem. Look at it visually with the R script `plot_blast_hit_stats.R`. (I never saw it being a problem so far, just a check for different data types) 

Full Command (type in the terminal)
```
Rscript plot_blast_hit_stats.R otus.custom.blast.table.modified 98 plots
```

command argument                   | description
-----------------------------------|----------------------------------------------
`RScript`							             | sources an R script and allows it to accept arguments from the command line
`plot_blast_hit_stats.R`				   | the script you are sourcing
`otus.custom.blast.table.modified` | the modified blast table produced in step 4.
`98`								               | the pident cutoff you chose to filter your sequences by
`plots`							               | the folder your generated plots will be saved in (this folder is created if it doesn't exist already)
`https://cran.mtu.edu`             | OPTIONAL argument (this is the default otherwise)

Note: This script will automatically install the reshape package temporarily if you don't have it already. If you get a bug, maybe this is the problem. Try opening R and typing `install.packages("reshape")` (and submit an issue for me even if that fixed it!).  
  
generated files:  

* `plots/BLAST_hits_used_for_pidents_0-100.png`
* `plots/BLAST_hits_used_for_pidents_0-100_only_incorrect_hits.png`
* `plots/BLAST_hits_used_for_pidents_0-100.csv`  

These plots show the percent of times that each BLAST hit was the recalculated best hit.
The .csv file is the data table used to make the plots.
Use these to check that returning the top 5 BLAST hits is enough, i.e. you are not missing 
alignments that would have been better when re-calculated to full-length percent identity.
This is shown by the re-calculated percent identity cutoff, with the idea being that if you 
are missing "better" hits but the "better" ones are still total crap, then it doesn't matter
if you missed them.  

Basically: look at the plot.  If it isn't almost zero for hit #5 then go back to step 2 and 
make BLAST report more than 5 hits, for example say `-max_target_seqs 10` instead of 
`-max_target_seqs 5`. Then repeat the other steps up to here and plot again, and check that
it's almost 0% at hit 10.  If it's still not we have a serious problem, please tell me!!  

note: if there is a tie where two hits are equally good at 5th place, I think BLAST will report both
and label one of them hit # 6.  So if you have an extra hit number, it doesn't mean there's a problem.

__________________________________________________________________________________________

# <span style="color:SteelBlue">7. recover missing seqIDs</span>

Blast has a built in reporting cutoff based on evalue.  The blast expect value depends on
the length of the hit and the size of the database, and it reflects how frequently you 
would see a hit of that quality by chance. The default evalue cutoff is 10, which means 
blast does not report a match that you'd see 10 or more times by chance.  For more about
the evalue statistics, see: http://www.ncbi.nlm.nih.gov/BLAST/tutorial/Altschul-1.html  

The python script `find_seqIDs_blast_removed.py` is used to find all of the 
sequence IDs in the original fasta file that do not appear in the blast output.  The python 
script then creates a new file in the same format as step 5's R script output file that
is a newline-delimited list of the missing sequence IDs.  

The bash command cat concatenates these missing ids with the ids below the chosen cutoff
pident.  That is because the ids blast didn't report hits for had even worse pidents than 
the ones that didn't make the R script cutoff, so they belong in the set that will be 
classified by the general database.  

Full Two Commands (type in terminal):
```
python find_seqIDs_blast_removed.py otus.fasta otus.custom.blast.table.modified ids.missing
cat ids.below.98 ids.missing > ids.below.98.all
```						

command argument                   | description
-----------------------------------|----------------------------------------------
`python`							             | opens the python program to source the script
`find_seqIDs_blast_removed.py`	   | python script you're sourcing
`otus.fasta`						           | original fasta file of your sequences from step 0 (this contains all the seqIDs)
`otus.FW.blast.table.modified`	   | reformatted blast results from step 4 (this contains all the seqIDs reported by BLAST)
`ids.missing`						           | the output file of seqIDs that were left out of BLAST results.  Its format is new line delimited seqIDs, no header
	
command argument                   | description
-----------------------------------|----------------------------------------------
`cat`								               | bash function that concatenates two files
`ids.below.98`					           | seqIDs below your cutoff from R script in step 5.
`ids.missing`						           | seqIDs not returned by BLAST, from this step, above.
`> ids.below.98.all`				       | combine those two files into this new one. <br> this file name now contains all the seqIDs you will classify in the general taxonomy database
									
__________________________________________________________________________________________

# <span style="color:SteelBlue">8. create fasta of seqIDs</span>

The create_fastas_given_seqIDs.py takes the sequence IDs selected using the blast output 
and finds them in the original query fasta file.  
It then creates a new fasta file containing just the desired sequences.  

The script is run twice, first to create the fasta file for seqIDs above the pident cutoff,
second to create the fasta file for seqIDs below the pident cutoff.  These fasta files will 
be classified with the custom and general databases, respectively.

Full Two Commands (type in terminal):
```
python create_fastas_given_seqIDs.py ids.above.98 otus.fasta otus.above.98.fasta
python create_fastas_given_seqIDs.py ids.below.98.all otus.fasta otus.below.98.fasta
```

command argument                   | description
-----------------------------------|----------------------------------------------
`python`              						 |	opens the python program to souce the script
`create_fastas_given_seqIDs.py`    |	the python script you're sourcing 
`ids.above.98`            				 |	the file of seqIDs at or above your cutoff from step 5
`ids.below.98.all`          			 |	the file of all seqIDs below your cutoff from step 7
`otus.fasta`            					 |	the original fasta file of all your OTU sequences from step 0
`otus.above.98.fasta`       			 |	the output file with fasta sequences at or above your cutoff
`otus.below.98.fasta`       			 |	the output file with fasta sequences below your cutoff<br>NOTE: if this output file already exist the script will delete it before starting.
	
__________________________________________________________________________________________

# <span style="color:SteelBlue">9. assign taxonomy</span>

The `classify.seqs()` command in mothur classifies sequences using a specified algorithm 
and a provided taxonomy database.  I use the default algorithm (wang with kmer size 8), 
and ask it to show bootstrap values. The output file is a list of sequence ID's next to
their assigned taxonomy.

Full Two Commands (type in terminal):
```
mothur "#classify.seqs(fasta=otus.above.98.fasta, template=custom.fasta,  taxonomy=custom.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
mothur "#classify.seqs(fasta=otus.below.98.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
```

input file names        | description
------------------------|----------------------------------------------
`otus.above.98.fasta` 	|	this is the fasta file containing only seqIDs >= your cutoff, from step 8
`otus.below.98.fasta` 	|	this is the fasta file containing only seqIDs < your cutoff, from step 8
`custom.fasta`      		|	this is the fasta file for your small custom taxonomy database (ie freshwater) 
`general.fasta`     		|	this is the fasta file for your large general taxonomy database (ie green genes) 
`custom.taxonomy`   		|	this is the .taxonomy file for your small custom taxonomy database (ie freshwater)
`general.taxonomy`    	|	this is the .taxonomy file for your large general taxonomy database (ie freshwater)

mothur flag     | description
----------------|----------------------------------------------
`fasta=`		    | path to the .fasta file you want classified
`template=`	    | path to the .fasta file of the taxonomy database
`taxonomy=`	    | path to the taxonomy file of the taxonomy database
`method=`		    | algorithm for assigning taxonomy. default is wang.
`probs=`		    | T or F, show the bootstrap probabilities or not?
`cutoff=`	    	| minimum bootstrap value for getting a name instead of unclassified<br>The default (v38) is `=80`, but you should say `=0`.<br>This workflow let's you apply a bootstrap cutoff after the fact so you can see everything 1st, and you have the option to use a different cutoff for the two databases.  
`processors=`   | the number of processors on your computer to run it on<br>note: mothur has a bug where this only works on windows and unix, mac only uses 1. 

output file names                         | description
------------------------------------------|----------------------------------------------
`otus.above.98.custom.wang.taxonomy`			| This is the custom taxonomy file that you keep!
`otus.above.98.custom.wang.tax.summary`		| you don't need it
`otus.below.98.general.wang.taxonomy`			| This is the general taxonomy file that you keep!
`otus.below.98.general.wang.tax.summary`	| you don't need it

(note you have no control over the name extensions added)

What the silently generated output files are (these are the databases mothur creates):  
<style>
.nobullet li {
  list-style-type: none;
}
</style>

<div class="nobullet">
* general.8mer  
*	general.general.8mer.numNonZero  
*	general.general.8mer.prob  
*	general.tree.sum  
*	general.tree.train  
*	custom.8mer  
*	custom.custom.8mer.numNonZero  
*	custom.custom.8mer.prob  
*	custom.tree.sum  
*	custom.tree.train  
</div>
	
Note: these database files take a long time to generate and are based only on the taxonomy database,
not on your OTU file. That means that you can re-use them and (for the general one at least) save
20 minutes the next time you use classify.seqs with the general database. This is also why if you
are trying multiple percent identity cutoffs you should run through one all the way first and then
do the next ones in paralelle (as done in RunSteps_1-14.sh).  The next steps will use the existing 
8-mer files and save 20min generating them. FYI they are bigger files though, so make sure you delete at the end.  
	
NOTE: these bootstrap percent confidence values are NOT the confidence that the taxonomy 
assignment is *correct*, just that it is *repeatable* in that database.  This is another 
paremeter that we could explore changing more in the future.  It's possible it should be different
in the different databases also because of the different database sizes.  I left cutoff out
in this command so that you can explore the different results of it later, in steps 13-14. 
You can choose a different cutoff for the different databases if you want.

__________________________________________________________________________________________

# <span style="color:SteelBlue">10. combine taxonomy files</span>


Concatenate the two taxonomy files to create one complete one.  You can very simply just 
combine them because there are no duplicate sequences between them.  The cat command in bash
concatenates two files into one.  You also choose your final file name here.

Full Command (type in terminal):
```
cat otus.above.98.custom.wang.taxonomy otus.below.98.general.wang.taxonomy > otus.98.taxonomy
```

Command syntax             | Description
---------------------------|-------------------------------------------
`cat file1 file2 > file3`	 | "combine file1 and file2 into file 3"
								
file names                              | description
----------------------------------------|----------------------------------------------
`otus.above.98.custom.wang.taxonomy`		| the taxonomy file for sequences classified with custom database
`otus.below.98.general.wang.taxonomy`		| the taxonomy file for sequences classified with general database
`otus.98.taxonomy`							            | the name you choose for the output complete taxonomy file for all your sequences.<br>I'm going with `otus.pidentcutoff.taxonomy`

The taxonomy files formatted with a tab separating the sequence ID, semicolons separating each taxon level, and a semicolon at the end of the line. Example format where 1,2,3,4,5 are the names of sequence IDs:  
```
1	Bacteria(100);Actinobacteria(100);Actinobacteria(100);Frankiales(100);acI(100);acI-B(98);acI-B1(98);
2	Bacteria(100);Actinobacteria(99);Actinobacteria(99);Frankiales(99);acI(98);acI-A(93);acI-A6(70);
3	Bacteria(100);Actinobacteria(100);Actinobacteria(100);Frankiales(100);acTH1(100);acTH1-A(100);acTH1-A1(100);
4	Bacteria(100);Proteobacteria(100);Alphaproteobacteria(100);SAR11_clade(100);alfV(100);alfV-A(100);LD12(100);
5	Bacteria(100);Proteobacteria(100);Gammaproteobacteria(100);Betaproteobacteriales(100);betI(99);betI-A(99);Lhab-A1(92);
```

__________________________________________________________________________________________

# <span style="color:SteelBlue">11. general-only taxonomy</span>

__________________________________________________________________________________________

<span style="color:SteelBlue">Steps 11-14 are optional, used to decide the percent identity cutoff.</span>
__________________________________________________________________________________________

Get a large, general database-only classification of your otus.fasta file to compare too.  
Greengenes, our general database choice, is a huge database (1,262,986 sequences), so the 
taxonomy assignment clustering algorithm is likely to only settle on a given taxonomic 
assignment if it is unambiguously correct.  Therefore, we trust the upper level Greengenes
assignments more than our custom database, even though we trust the lower level taxonomic
assignments using our custom database more.

So in this step you assign taxonomy with the general database using mothur, and then
rename the output file something easy to work with using bash.

Full Two Commands (type in terminal):
```
mothur "#classify.seqs(fasta=otus.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
cat otus.general.wang.taxonomy > otus.general.taxonomy
```

(See step 9 for a detailed explanation of these two commands and their arguments.)  

file names                   | description
-----------------------------|----------------------------------------------
`otus.fasta`					       | the original fasta file of your OTU sequences
`general.fasta`				       | the fasta file of the large, general database
`general.taxonomy`			     | the taxonomy file of the large, general database
`otus.general.wang.taxonomy` | the taxonomy of your OTUs assigned by the general database<br>this is the default name created by mothur
`otus.general.taxonomy`		   | the otus.general.wang.taxonomy file renamed


__________________________________________________________________________________________


# <span style="color:SteelBlue">12. reformat taxonomy files</span>

__________________________________________________________________________________________

<span style="color:SteelBlue">**HALF OF THIS STEP IS NOT OPTIONAL**</span>
__________________________________________________________________________________________


The R script in step 13 requires semicolon delimited taxonomy files.  The mothur output
.taxonomy files are delimited with both tabs and semicolons.

Reformat both files you will compare:  

*	the otus.taxonomy file created in step 10
*	the otus.general.taxonomy file created in step 11  

Find: tab  
Replace: semicolon  

Full Four Commands (Type in Terminal):  
```
sed 's/[[:blank:]]/\;/' <otus.98.taxonomy >otus.98.taxonomy.reformatted
mv otus.98.taxonomy.reformatted otus.98.taxonomy

# (optional- only do if did step 11):
sed 's/[[:blank:]]/\;/' <otus.general.taxonomy >otus.general.taxonomy.reformatted
mv otus.general.taxonomy.reformatted otus.general.taxonomy
```

Command syntax: `sed 's/find/replace/ <input >output`  
had to use blank because it doesn't recognize `\t` as tab for some reason, need a shell script you source with an actual tab in it. Or blank is convenient, since there is no other white space anyway.  

The new format is all semicolon delimited. Example format where 1,2,3,4,5 are the names of sequence IDs:  
```
1;Bacteria(100);Actinobacteria(100);Actinobacteria(100);Frankiales(100);acI(100);acI-B(98);acI-B1(98);
2;Bacteria(100);Actinobacteria(99);Actinobacteria(99);Frankiales(99);acI(98);acI-A(93);acI-A6(70);
3;Bacteria(100);Actinobacteria(100);Actinobacteria(100);Frankiales(100);acTH1(100);acTH1-A(100);acTH1-A1(100);
4;Bacteria(100);Proteobacteria(100);Alphaproteobacteria(100);SAR11_clade(100);alfV(100);alfV-A(100);LD12(100);
5;Bacteria(100);Proteobacteria(100);Gammaproteobacteria(100);Betaproteobacteriales(100);betI(99);betI-A(99);Lhab-A1(92);
```  

__________________________________________________________________________________________

# <span style="color:SteelBlue">13. compare taxonomy files</span>

__________________________________________________________________________________________

<span style="color:SteelBlue">Steps 11-14 are optional, used to decide the percent identity cutoff.</span>
__________________________________________________________________________________________


The R script find_classification_disagreements.R  creates a folder containing a file for 
each upper taxonomic level (kingdom, phylum, class, order, lineage) that lists all of the 
classification disagreements at that taxonomic level between the custom + general taxonomy
database workflow and the general-only taxonomy database workflow. Note that this only 
compares classifications made in the custom database, it ignores differences between 
classifications that were both made by the general database (which can happen because 
the classification algorithm is stochastic.)  

This script also allows the user to choose a bootstrap %confidence cutoff under which all
the lower assignments are unclassified.  The script does not include unclassified names in 
its reporting of disagreements.  This allows you to ignore taxonomy assignment conflicts when
you don't trust the assignment anyway, and you can decide what you trust (60% is generally
considered the minimum cutoff you should use, 80% is the default in the mothur MiSeq SOP.)

Additionally, this script generates a final version of your taxonomy file with the applied 
bootstrap cutoff implemented.  The version made in step 10 contains all the taxonomy assignments,
even ones with very low bootstrap p-values.  This generates a .taxonomy file with the cutoff
applied, so that everything under that cutoff is named "unclassified"  Note that you can 
apply this cutoff in step 9 using the "cutoff = #" flag with the mothur command classify.seqs().
I didn't do it there though to make these analysis steps more flexible. The format of this file
is comma delimited, which is slightly different than the mothur output files that are 
semicolon deliminited between taxonomy levels and tab delimited between the seqID column and
the taxonomy names.

Note: you must create a new folder to save these results in before running the script.
	include the pident cutoff in your folder name, b/c the file names will not include that.
	(Suggested folder name and creation is below.)

Full Two Commands (type in terminal):
```
mkdir conflicts_98
Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 80 80
```
Note: you must enter all the arguments in this order.

command argument                      | description
--------------------------------------|----------------------------------------------
`Rscript`									            | this opens R to accept arguments from the command line
`find_classification_disagreements.R` | this is the R script you're sourcing
`otus.98.taxonomy`					          | this is the path to your otu taxonomy file created using both databases in step 10
`otus.general.taxonomy`					      | this is the path to your otu taxonomy file created using only the general database in step 11
`ids.above.98`							          | this is the path to the file created in step 4 that contains all of the sequence IDs above or equal to your pident cutoff
`conflicts_98`							          | this is the path to the folder you want to save the .csv results files in. You create this folder in this step with the mkdir command.
`98`										              | this is the pident cutoff you're using.
`80`									                | this is the bootstrap p-value cutoff for the custom database assigned sequences. This determines if a classification is good enough to be named or should be "unclassified." 
`80`										              | this is the bootstrap p-value cutoff for the general database assigned sequences. This determines if a classification is good enough to be named or should be "unclassified." 


Generated files in your conflicts folders:  

*	kingdom_conflicts.csv
*	phylum_conflicts.csv
*	class_conflicts.csv
*	order_conflicts.csv
*	lineage_conflicts.csv
*	conflicts_summary.csv


__________________________________________________________________________________________

# <span style="color:SteelBlue">14. choose pident cutoff</span>

__________________________________________________________________________________________

<span style="color:SteelBlue">Steps 11-14 are optional, used to decide the percent identity cutoff.</span>
__________________________________________________________________________________________


**You have to repeat steps 5, 7-10, & 12-13 with multiple pident cutoffs to do this step.**

This step generates some plots that you can use to double check that your chosen cutoff is 
appropriate.  The plots are saved into the "plots" folder that you created in step 6.  In
order to examine the cutoff sensitivity, you have to run steps 5, 7-10, & 12-13 multiple times
with different pident cutoffs.  Fortunately the ~20 min of generating 8-mer databases in 
classify.seqs() in mothur will be faster because the mothur database files are not re-made.  

If you are working with clustered OTUs, you might want to skip this step to save time and just
use your clustering percent similarity as your pident cutoff. You've basically already made
the decision this step is agonizing over when you chose that, and the plot will not mean much 
if the sequences in it were already clustered. We recommend, if you're skipping this step,
to just choose a pident cutoff in the range of 97-99.  

Definitely consider using the `RunSteps` shell scripts if you are running these comparisons.
You could go through first with only 1 sample to make sure it works, then just set up the full run overnight or on a server.  

Full Command (type in terminal):
```
Rscript plot_classification_disagreements.R otus.abund plots regular NA NA conflicts_94 ids.above.94 94 conflicts_96 ids.above.96 96 conflicts_98 ids.above.98 98
```

command argument                      | description
--------------------------------------|----------------------------------------------
`Rscript`									            | Calls program R in a way that accepts command line arguments
`plot_classification_disagreements.R` | name of the script you are calling
`otus.abund`								          | OTU relative abundance table<br>This script will generate the total.reads.per.seqID.csv file from that.  It needs it to compare by % reads.
`plots`									              | path to folder you are saving the plots into.<br>note: this folder must already exist. you made it in step 6.
`regular`									            | placeholder, this is only used in the step where you plot forcing<br>Note: this one must say exactly "regular"
`NA`										              | also placeholder for forcing, could say anything
`NA`										              | also placeholder for forcing, could say anything
`conflicts_94`							          | path to folder containing taxonomy disagreements between this cutom+general workflow and the general database alone. You made this folder in step 13.
`ids.above.94`							          | path to the file that lists all the seqIDs meeting your pident cutoff that were therefore classified with your custom databse. You made this file in step 4.
`94`										              | pident cutoff used in the previous two arguments
`conflicts_96`							          | folder of taxonomy disagreements
`ids.above.96`							          | file of custom-classified seqIDs	
`96`										              | pident cutoff for previous two arguments
`...`										              | additional arguments <br>you can have as many pident cutoffs compared as you want.  Just keep listing them in this format:<br>folder_path<br>ids.file<br>pident folder_path<br>ids.file<br>pident<br>...

This R script can also be used after running only one percent identity through steps 11-13. In that case, it only generates an intermediate file that's used for step 15.5 since there's no pidents to compare. You would do this if you don't want to compare different percent identity cutoffs, but you do want to look at the "improvement" plots in step 15.5. **The syntax details for this useage are in step 15.**  

__________________________________________________________________________________________

# <span style="color:SteelBlue">15. make final taxonomy file</span>

Based on your results from step 14, choose which pident cutoff to use.  Use the same script 
from step 13, except this time specify "final."  This final taxonomy file is different from 
files created in step 9-10 because it applies your clustering bootstrap pvalue cutoff, calling
everything below that cutoff "unclassified."  

Recall that choosing that cutoff was left out of the mothur command to allow flexibility in
analyzing results.  The "final" argument to this script is left out in step 13 because it takes
longer when it is included.  This is because in finding the classification disagreements, the
script only compares classifications assigned by the custom database, which is a subset 
of all of the classifications.

Full Command options (Type in Terminal):    
**yes** = ran or will run that step(s)  
**no** = skipped or will skip that step(s)  
  
**yes 11-14, yes 15.5.a:** (compared pidents and and want to look at improvement)
```
Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 80 80 final
```  
  
**yes 11-14, no 15.5.a:** (compared pidents, but don't care about improvement plots)
```
Rscript find_classification_disagreements.R otus.98.taxonomy quickie ids.above.98 conflicts_98 98 80 80 final
```

**yes 11-13, no 14, yes 15.5.a:** (chose pident without comparing, but still want to see improvement plots)
```
Rscript plot_classification_disagreements.R otus.abund MakeSeqIDReadsOnly
Rscript find_classification_disagreements.R otus.98.taxonomy quickie ids.above.98 conflicts_98 98 80 80 final
```

**no 11-14, no 15.5.a:**  (chose pident without comparing, no need to see extra plots either.)
```
Rscript find_classification_disagreements.R otus.98.taxonomy quickie ids.above.98 conflicts_98 98 80 80 final
```

command argument                      | description
--------------------------------------|----------------------------------------------
`Rscript`									            | this opens R to accept arguments from the command line
`find_classification_disagreements.R` | this is the R script you're sourcing
`otus.98.taxonomy`        						| this is the path to your otu taxonomy file created using both databases in step 10
`otus.general.taxonomy`<br><br>OR<br><br>`quickie` | `otus.general.taxonomy` is the path to your otu taxonomy file created using only the general database in step 11. It's not used for the final file generation, but it is used in this step to generate a file for step 15.5.a, so that's why you still need to specify the path. <br><br> use the `quickie` option if you skipped optional checks 11-14, and also if you did those steps but are going to skip optional step 15.5.a.  
`ids.above.98`							          | this is the path to the file created in step 4 that contains all of the sequence IDs above or equal to your pident cutoff
`conflicts_98`							          | this is the path to the folder you want to save the .csv results files in. You create this folder in this step with the mkdir command.
`98`										              | this is the pident cutoff you're using.
`80`									                | this is the bootstrap p-value cutoff for the custom database assigned sequences. This determines if a classification is good enough to be named or should be "unclassified." 
`80`										              | this is the bootstrap p-value cutoff for the general database assigned sequences. This determines if a classification is good enough to be named or should be "unclassified." 
`final`									              | this flag lets the script know you want a final file generated. Therefore it applies the bootstrap p-value cutoff to the entire script instead of just the custom-classified seqIDs. That's why it will take longer this time you run the script.

command argument                      | description
--------------------------------------|----------------------------------------------
`Rscript`									            | Calls program R in a way that accepts command line arguments
`plot_classification_disagreements.R` | name of the script you are calling
`otus.abund`								          | OTU relative abundance table<br>This script will generate the total.reads.per.seqID.csv file from that.  It needs it to compare by % reads.
`MakeSeqIDReadsOnly`                  | Only make the seqID.reads table. Would use this option if you skip step 14 (comparing different pidents), but still want to do step 15.5.a where you pat yourself on the back and compare the general-only classifications. Note you still need to have done steps 11-13 where you classify with only the general database!


__________________________________________________________________________________________

# <span style="color:SteelBlue">15.5 plot TaxAss benefits</span>

### <span style="color:SteelBlue">15.5 OPTIONAL: plot benefits of using this workflow (R)</span>

_____________________________________

### 15.5.a. Plot improvement over using general database alone

In this step two plots are generated that show you the benefit of using the custom workflow.
The plots show the number of known taxonomic assignments by either % of total OTUs or % of 
total reads.  Basically, the script sums up everything that is not called "unclassified"
in the final TaxAss taxonomy file and the general database taxonomy file with the bootstrap
p-value cutoffs applied. This total determines the bar heights. Then the script compares only 
the OTUs classified by the custom database to how they would be classified by the general database. 
OTUs that get a new name are called "reclassified" (yellow), and OTUs unclassified by the general
database that get classified by the custom database are called "newly named" (red). OTUs classified
by the general database both ways are considered "unchanged" even if though some of their names, 
and especially whether they are classified or unclassified, sometimes changes due to the stochastic 
nature of the RDP classifier.

Full Command Options (Type into terminal):  
```
Rscript plot_classification_improvement.R final.taxonomy.pvalues final.general.pvalues total.reads.per.seqID.csv plots final.taxonomy.names final.general.names ids.above.98
```

command argument                      | description
--------------------------------------|----------------------------------------------
`final.taxonomy.pvalues`			        | a file of p-values corresponding to the final taxonomy file you generated in step 15.  This file, with this name, was automatically generated in step 15 so it is already in your working directory.  
`final.general.pvalues` 			        | a file of p-values corresponding to the general-classified taxonomy after the classification p-value cutoff has been applied. This file, with this name, was automatically generated in step 15 so it is already in your working directory.  
`total.reads.per.seqID`		      	    | a file that lists each seqID and the total number of reads for that seqID.  This file, with this name, was automatically generated in step 14, using your otus.abund table, so it is already in your working directory.
`plots`						  	                | the name of the folder that plots are saved into.  you created this folder in step 6.
`final.taxonomy.names`			          | the names-only of the final taxonomy file. It's generated automatically, and deleted as an intermediate file during clean-up.
`final.general.names`				          | the names-only of the general-only taxonomy file. It's generated automatically, and deleted as an intermediate file during clean-up.
`ids.above.98`                        | the seqIDs of OTUs above the percent identity cutoff (classified by custom). This file is automatically generated in step 5.
_____________________________________

### 15.5.b. Plot improvement over using custom database alone

In this step the classifications you get using the custom database alone are compared to the final workflow
taxonomy file generated in step 15.  The plots created show the "forcing" that would occur from using only
the small database.  Forcing occurs because the RDP classifier classifies sequences stochastically, putting
them with the most similar sequence *in your database*.  If there are no similar sequences and the database is 
large, then the sequence will be put somewhere different each time, end up with a low p-value, and be called
unclassified.  However in a smaller database, it's possible that a dissimilar sequence might be put reliably
in the same classification because it is most similar to that, even though the sequence itself is very dissimilar.
This is what I call forcing.  These plots take longer to generate because you have to do an additional classification 
of your OTUs with the custom database alone.

Full Commands (Type into terminal):  
```
mothur "#classify.seqs(fasta=otus.fasta, template=custom.fasta, taxonomy=custom.taxonomy, method=wang, probs=T, processors=2, cutoff=0)"
cat otus.custom.wang.taxonomy > otus.custom.taxonomy

sed 's/[[:blank:]]/\;/' <otus.custom.taxonomy >otus.custom.taxonomy.reformatted
mv otus.custom.taxonomy.reformatted otus.custom.taxonomy

mkdir conflicts_forcing
Rscript find_classification_disagreements.R otus.custom.taxonomy otus.98.80.80.taxonomy ids.above.98 conflicts_forcing NA 80 80 forcing

Rscript plot_classification_disagreements.R otus.abund plots conflicts_forcing otus.custom.80.taxonomy otus.98.80.80.taxonomy
```

command argument                      | description
--------------------------------------|----------------------------------------------
`Rscript`									            | Calls program R in a way that accepts command line arguments
`plot_classification_disagreements.R` | name of the script you are calling
`NA`										              | can leave as `NA` if you ran step 14, which generated the `total.reads.per.seqID.csv` file. Otherwise this should be `otus.abund` to generate that file for the first time.
`plots`									              | path to folder you are saving the plots into.<br>note: this folder must already exist. you made it in step 6.
`conflicts_forcing`									  | folder of taxonomy disagreements generated in 15.5.b in `find.classification.disagreements.R`  
`otus.custom.80.taxonomy`             | the classifications using only the custom database, generated in 15.5.b by `find_classification_disagreements.R`
`otus.98.85.70.taxonomy`						  | the final workflow taxonomy generated in step 15


__________________________________________________________________________________________

# <span style="color:SteelBlue">16. tidy up</span> {.tabset}

## Easiest way

This step tidies up your working directory folder by removing intermediate files you don't 
need anymore and moving remaining files into orgainized folders.  
Note: these bash commands only work if you've been using the same names as the workflow.  
Note: go through these commands in order, <span style="color:SteelBlue">following the tabs from left to right.</span>  

Easiest way is to do:
```
./RunStep_16.sh
```  

You end up with these folders:  

* **data**  
  has your starting datafiles and the final taxonomy file
* **analysis**  
  has the stuff like plots that you used to make processing decisions  
* **scripts**  
  all the scripts you used, to save to be reproducible  
* **databases**  
  all the databases you used, to save to be reproducible  
  (you might want to delete this to save space though)


<br><br>
__________________________________________________________________________________________

<span style="color:SteelBlue">~The end~</span>  
__________________________________________________________________________________________


## 16.1 delete

**16.1 delete intermediate files you don't need anymore**

Full Command (Type in Terminal):
```
rm custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy otus.custom.taxonomy otus.custom.[0-9]* custom.general* *pvalues total* final*names
```

What each of these intermediate files is (and why you might want to keep them):  
```
custom.db.*		
				The blast database files from step 1:	custom.db.nhr
														custom.db.nin
														custom.db.nog
														custom.db.nsd
														custom.db.nsi
														custom.db.nsq
				(saves time if you want to re-run blast on the same taxonomy database)

custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree*
				The mothur database files from step 9:	custom.8mer
														custom.custom.8mer.numNonZero
														custom.custom.8mer.prob
														custom.tree.sum
														custom.tree.train
														general.8mer
														general.general.8mer.numNonZero
														general.general.8mer.prob
														general.tree.sum
														general.tree.train
				(saves time if you want to re-run classify seqs with the same taxonomy database)
				The comparison taxonomy file from step 11.5: custom.custom.taxonomy 
				(was only needed for database comparison)

*wang* mothur.*.logfile
				The mothur classify seqs output files from steps 9, 11, 11.5, 15.5.b.: ex:	otus.above.98.custom.wang.tax.summary
																							otus.above.98.custom.wang.taxonomy
																							otus.below.98.general.wang.flip.accnos
																							otus.below.98.general.wang.tax.summary
																							otus.below.98.general.wang.taxonomy
				(these were re-named if they are versions to keep.)
				The mothur log files: ex: mothur.1471668348.logfile
				(there is no reason to keep this, especially if you saved terminal output yourself.)

otus.custom.blast*
				The blast results from steps 2-4:	otus.custom.blast
													otus.custom.blast.table
													otus.custom.blast.table.modified
				(the .table and .table.modified are easy to regenerate, the raw blast results may take longer)
				
ids*			
				lists of seqIDs from steps 5 and 7: ex:	ids.above.98
														ids.below.98
														ids.below.98.all
														ids.missing
 				(not needed once you have the fasta files)
 				
otus.below*.fasta otus.above*.fasta
				fasta files created for separate custom & general classification made in step 8: ex:	otus.above.98.fasta
																										otus.below.98.fasta
				(not needed post-classification.)

otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy otus.custom.taxonomy otus.custom.[0-9]* custom.general*
				classifications for pident comparisons in steps 13 and 14: ex:	otus.100.taxonomy
																				otus.90.taxonomy
																				otus.general.taxonomy
				classifications for database comparisons in steps 15.5.b:	otus.custom.taxonomy
																			otus.custom.80.taxonomy														
				(these files don't have p-value cutoffs applied (i.e. nothing's called unclassified), so they are not final versions) 
				For saving additional cutoff versions of your data instead of using these files do: 
					re-run step 15 to get additional "final" versions.
					re-run step 11 with an additional "cutoff=" flag.

*pvalues total*	final*names
				These are files generated in step 13 to use in 15.5.a:	final.general.pvalues
																		final.taxonomy.pvalues
																		final.general.names
																		final.taxonomy.names
				This file is generated in optional step 14 or 15:	total.reads.per.seqID.csv
```
Note: if for some reason you want to keep these files, you can either skip this step
or instead of rm use the `mv filenames foldername` command to move them to a folder instead.
Some of these intermediate files are quite large though, so keep that in mind if your computer's filling up.


## 16.2 scripts

**16.2 save scripts used in a scripts folder**

Full 2 commands (Type in Terminal):
```
mkdir scripts
mv *.py *.R *.sh *.md *.Rmd *.html scripts
```

By saving all the script versions you used to create your data you can reproduce it.
Alternatively for reproducible data note the github SHA number you retreived them from in a README.
Find this on github, click commits tab, click clipboard icon on most recent commit to copy the SHA identifier.


## 16.3 analysis

**16.3 save files used in analyzing your results in analysis folder**

These are technically also "intermediate" files, but they're the ones you used to make analysis decisions so might be nice to refer back to.

Full 2 commands (Type in Terminal):
```
mkdir analysis/
mv conflicts* plots/ analysis/
```

You can delete this instead if just want to get on with
your life already. Instead of the two commands, type:  
```
rm -r conflicts* plots/
```

## 16.4 data

**16.4 save your actual data files in a folder called data**

Full Two commands (Type in Terminal):  

```
mkdir data
mv otus* *.rds data/
```

Yeyy!  This is what you're gonna use to actually do stuff now!!  
It includes:	 

file                    | description
------------------------|------------------------------------------
otus.98.70.70.taxonomy	|	your final taxonomy file
				otus.abund			|		the relative abundance OTU table you started with
				otus.fasta			|		the OTU fasta file you started with  
		seqtab_nochim.rds   | your starting file if you started with dada2 QC


## 16.5 databases

**16.5 save the version of the taxonomy databases you used in a databases folder**

Full Two Commands (type in terminal):
```
mkdir databases
mv *.taxonomy *.fasta databases
```

Saving these versions of the databases will let you reproduce your data. Alternatively
you could make note of the versions you used and how you downloaded them in a README file.
These can be relatively large files.  
  
If you don't care at all about being reproducible, all you really need to save is the stuff
in the data/ folder.  That's your actual data.  

<br><br>
__________________________________________________________________________________________

<span style="color:SteelBlue">~The end~</span>  
__________________________________________________________________________________________